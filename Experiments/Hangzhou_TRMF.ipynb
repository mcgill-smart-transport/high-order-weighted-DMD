{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Temporal regularized matrix factorization (TRMF) for metro OD forecasting. Code is adapted from [https://github.com/xinychen/transdim](https://github.com/xinychen/transdim)\n",
    "\n",
    "Original paper for TRMF:\n",
    "- Hsiang-Fu Yu, Nikhil Rao, Inderjit S. Dhillon, 2016. Temporal regularized matrix factorization for high-dimensional time series prediction. 30th Conference on Neural Information Processing Systems (NIPS 2016),"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from numpy.linalg import inv as inv\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def reset_random_seeds(n=1):\n",
    "    os.environ['PYTHONHASHSEED'] = str(n)\n",
    "    np.random.seed(n)\n",
    "    random.seed(n)\n",
    "\n",
    "\n",
    "def kr_prod(a, b):\n",
    "    return np.einsum('ir, jr -> ijr', a, b).reshape(a.shape[0] * b.shape[0], -1)\n",
    "\n",
    "\n",
    "def TRMF(train_data, init, time_lags, lambda_w, lambda_x, lambda_theta, eta, maxiter, multi_steps=1, display=10):\n",
    "    start = time.time()\n",
    "    W = init[\"W\"]\n",
    "    X = init[\"X\"]\n",
    "    theta = init[\"theta\"]\n",
    "\n",
    "    dim1, dim2 = train_data.shape\n",
    "    binary_mat = np.zeros((dim1, dim2))\n",
    "    position = np.where((train_data != 0))\n",
    "    binary_mat[position] = 1\n",
    "\n",
    "    d = len(time_lags)\n",
    "    r = theta.shape[1]\n",
    "\n",
    "    for iter in range(maxiter):\n",
    "        if (iter + 1) % display == 0:\n",
    "            print('Time step: {} time {}'.format(iter + 1, time.time() - start))\n",
    "        var1 = X.T\n",
    "        var2 = kr_prod(var1, var1)\n",
    "        var3 = np.matmul(var2, binary_mat.T)\n",
    "        var4 = np.matmul(var1, train_data.T)\n",
    "        for i in range(dim1):\n",
    "            W[i, :] = np.matmul(inv((var3[:, i].reshape([r, r])) + lambda_w * np.eye(r)), var4[:, i])\n",
    "\n",
    "        var1 = W.T\n",
    "        var2 = kr_prod(var1, var1)\n",
    "        var3 = np.matmul(var2, binary_mat)\n",
    "        var4 = np.matmul(var1, train_data)\n",
    "        for t in range(dim2):\n",
    "            Mt = np.zeros((r, r))\n",
    "            Nt = np.zeros(r)\n",
    "            if t < max(time_lags):\n",
    "                Pt = np.zeros((r, r))\n",
    "                Qt = np.zeros(r)\n",
    "            else:\n",
    "                Pt = np.eye(r)\n",
    "                Qt = np.einsum('ij, ij -> j', theta, X[t - time_lags, :])\n",
    "            if t < dim2 - np.min(time_lags):\n",
    "                if t >= np.max(time_lags) and t < dim2 - np.max(time_lags):\n",
    "                    index = list(range(0, d))\n",
    "                else:\n",
    "                    index = list(np.where((t + time_lags >= np.max(time_lags)) & (t + time_lags < dim2)))[0]\n",
    "                for k in index:\n",
    "                    theta0 = theta.copy()\n",
    "                    theta0[k, :] = 0\n",
    "                    Mt = Mt + np.diag(theta[k, :] ** 2)\n",
    "                    Nt = Nt + np.multiply(theta[k, :], (X[t + time_lags[k], :]\n",
    "                                                        - np.einsum('ij, ij -> j', theta0,\n",
    "                                                                    X[t + time_lags[k] - time_lags, :])))\n",
    "                X[t, :] = np.matmul(inv(var3[:, t].reshape([r, r])\n",
    "                                        + lambda_x * Pt + lambda_x * Mt + lambda_x * eta * np.eye(r)),\n",
    "                                    (var4[:, t] + lambda_x * Qt + lambda_x * Nt))\n",
    "            elif t >= dim2 - np.min(time_lags):\n",
    "                X[t, :] = np.matmul(inv(var3[:, t].reshape([r, r]) + lambda_x * Pt\n",
    "                                        + lambda_x * eta * np.eye(r)), (var4[:, t] + Qt))\n",
    "        for k in range(d):\n",
    "            var1 = X[np.max(time_lags) - time_lags[k]: dim2 - time_lags[k], :]\n",
    "            var2 = inv(np.diag(np.einsum('ij, ij -> j', var1, var1)) + (lambda_theta / lambda_x) * np.eye(r))\n",
    "            var3 = np.zeros(r)\n",
    "            for t in range(np.max(time_lags) - time_lags[k], dim2 - time_lags[k]):\n",
    "                var3 = var3 + np.multiply(X[t, :],\n",
    "                                          (X[t + time_lags[k], :]\n",
    "                                           - np.einsum('ij, ij -> j', theta, X[t + time_lags[k] - time_lags, :])\n",
    "                                           + np.multiply(theta[k, :], X[t, :])))\n",
    "            theta[k, :] = np.matmul(var2, var3)\n",
    "\n",
    "    X_new = np.zeros((dim2 + multi_steps, rank))\n",
    "    X_new[0: dim2, :] = X.copy()\n",
    "    for step in range(multi_steps):\n",
    "        X_new[dim2 + step, :] = np.einsum('ij, ij -> j', theta, X_new[dim2 + step - time_lags, :])\n",
    "\n",
    "    return W, X_new, theta, np.matmul(W, X_new[dim2: dim2 + multi_steps, :].T)\n",
    "\n",
    "\n",
    "def OnlineTRMF(sparse_vec, init, lambda_x, time_lags):\n",
    "    W = init[\"W\"]\n",
    "    X = init[\"X\"]\n",
    "    theta = init[\"theta\"]\n",
    "    dim = sparse_vec.shape[0]\n",
    "    t, rank = X.shape\n",
    "    position = np.where(sparse_vec != 0)\n",
    "    binary_vec = np.zeros(dim)\n",
    "    binary_vec[position] = 1\n",
    "\n",
    "    xt_tilde = np.einsum('ij, ij -> j', theta, X[t - 1 - time_lags, :])\n",
    "    var1 = W.T\n",
    "    var2 = kr_prod(var1, var1)\n",
    "    var_mu = np.matmul(var1, sparse_vec) + lambda_x * xt_tilde\n",
    "    inv_var_Lambda = inv(np.matmul(var2, binary_vec).reshape([rank, rank]) + lambda_x * np.eye(rank))\n",
    "    X[t - 1, :] = np.matmul(inv_var_Lambda, var_mu)\n",
    "    return X\n",
    "\n",
    "\n",
    "def st_prediction(train_data, time_lags, lambda_w, lambda_x, lambda_theta, eta,\n",
    "                  rank, pred_time_steps, maxiter, multi_steps=1, display=100):\n",
    "    start = time.time()\n",
    "    start_time = train_data.shape[1] - pred_time_steps\n",
    "    # dense_mat0 = dense_mat[:, 0: start_time]\n",
    "    train_data0 = train_data[:, 0: start_time]\n",
    "    dim1 = train_data0.shape[0]\n",
    "    dim2 = train_data0.shape[1]\n",
    "    max_time_lag = max(time_lags)\n",
    "    results = {step + 1: np.zeros((dim1, pred_time_steps)) for step in range(multi_steps)}\n",
    "\n",
    "    for t in range(pred_time_steps):\n",
    "        if t == 0:\n",
    "            init = {\"W\": 0.1 * np.random.rand(dim1, rank), \"X\": 0.1 * np.random.rand(dim2, rank),\n",
    "                    \"theta\": 0.1 * np.random.rand(time_lags.shape[0], rank)}\n",
    "            W, X, theta, mat_f = TRMF(train_data0, init, time_lags,\n",
    "                                      lambda_w, lambda_x, lambda_theta, eta, maxiter, multi_steps, display=display)\n",
    "            # Assign forecast to the corresponding step\n",
    "            for step in range(multi_steps):\n",
    "                results[step + 1][:, t] = mat_f[:, step]\n",
    "            X0 = X[dim2 - max_time_lag:dim2 + 1, :].copy()  # Keep recent max_time_lag + one-step forecast\n",
    "        else:\n",
    "            sparse_vec = train_data[:, start_time + t - 1]\n",
    "            if np.where(sparse_vec > 0)[0].shape[0] > rank:\n",
    "                init = {\"W\": W, \"X\": X0, \"theta\": theta}\n",
    "                X = OnlineTRMF(sparse_vec, init, lambda_x / dim2, time_lags)\n",
    "                X0 = np.zeros((max_time_lag + multi_steps, rank))\n",
    "                X0[0: max_time_lag, :] = X[1:, :]\n",
    "                for step in range(multi_steps):\n",
    "                    step_X = np.einsum('ij, ij -> j', theta, X0[max_time_lag + step - time_lags, :])\n",
    "                    X0[max_time_lag + step, :] = step_X\n",
    "                    results[step + 1][:, t] = W @ step_X\n",
    "                X0 = X0[:max_time_lag + 1, :]  # Keep recent max_time_lag + one-step forecast\n",
    "            else:\n",
    "                X = X0.copy()\n",
    "                X0 = np.zeros((max_time_lag + multi_steps, rank))\n",
    "                X0[0: max_time_lag, :] = X[1:, :]\n",
    "                for step in range(multi_steps):\n",
    "                    step_X = np.einsum('ij, ij -> j', theta, X0[max_time_lag + step - time_lags, :])\n",
    "                    X0[max_time_lag + step, :] = step_X\n",
    "                    results[step + 1][:, t] = W @ step_X\n",
    "                X0 = X0[:max_time_lag + 1, :]  # Keep recent max_time_lag + one-step forecast\n",
    "\n",
    "        if (t + 1) % 40 == 0:\n",
    "            print('Time step: {}, time {}'.format(t + 1, time.time() - start))\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data0 = loadmat('..//data//Hangzhou_OD.mat')\n",
    "data0 = data0['OD']\n",
    "data0 = remove_weekends(data0, start=1)\n",
    "\n",
    "train_idx = np.arange(0, 36 * 14)\n",
    "test_idx = np.arange(36 * 14, 36 * 19)\n",
    "num_s = 80\n",
    "\n",
    "# Subtract the mean in the training set\n",
    "data = data0.astype(np.float64)\n",
    "data_mean = data[:, train_idx].reshape([num_s * num_s, 36, -1], order='F')\n",
    "data_mean = data_mean.mean(axis=2)\n",
    "for i in range(19):\n",
    "    data[:, i * 36:(i + 1) * 36] = data[:, i * 36:(i + 1) * 36] - data_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameter tuning\n",
    "## Tune weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step: 100 time 79.45164084434509\n",
      "Time step: 200 time 159.3595895767212\n",
      "Time step: 300 time 239.56135749816895\n",
      "Time step: 40, time 242.61774325370789\n",
      "Time step: 80, time 244.84792494773865\n",
      "Time step: 120, time 247.15725874900818\n",
      "[3.0052290144005642]\n",
      "Time step: 100 time 77.43766212463379\n",
      "Time step: 200 time 154.6269087791443\n",
      "Time step: 300 time 232.30538177490234\n",
      "Time step: 40, time 235.30813121795654\n",
      "Time step: 80, time 237.46391034126282\n",
      "Time step: 120, time 239.5571985244751\n",
      "[3.0052290144005642, 2.9231605124035376]\n",
      "Time step: 100 time 77.11366987228394\n",
      "Time step: 200 time 155.49117469787598\n",
      "Time step: 300 time 233.71165561676025\n",
      "Time step: 40, time 236.46105670928955\n",
      "Time step: 80, time 238.53872323036194\n",
      "Time step: 120, time 240.8350956439972\n",
      "[3.0052290144005642, 2.9231605124035376, 2.867187013790351]\n",
      "Time step: 100 time 77.1600730419159\n",
      "Time step: 200 time 155.38090705871582\n",
      "Time step: 300 time 232.86850905418396\n",
      "Time step: 40, time 235.86785173416138\n",
      "Time step: 80, time 238.00800466537476\n",
      "Time step: 120, time 240.13254237174988\n",
      "[3.0052290144005642, 2.9231605124035376, 2.867187013790351, 2.877562962365891]\n",
      "Time step: 100 time 77.4685320854187\n",
      "Time step: 200 time 155.70872807502747\n",
      "Time step: 300 time 234.64775609970093\n",
      "Time step: 40, time 237.53774523735046\n",
      "Time step: 80, time 239.67789602279663\n",
      "Time step: 120, time 241.75809335708618\n",
      "[3.0052290144005642, 2.9231605124035376, 2.867187013790351, 2.877562962365891, 2.8844083229661277]\n",
      "Time step: 100 time 76.81596112251282\n",
      "Time step: 200 time 154.72331309318542\n",
      "Time step: 300 time 232.25867295265198\n",
      "Time step: 40, time 235.03928470611572\n",
      "Time step: 80, time 237.2129771709442\n",
      "Time step: 120, time 239.49373054504395\n",
      "[3.0052290144005642, 2.9231605124035376, 2.867187013790351, 2.877562962365891, 2.8844083229661277, 2.926580051170401]\n",
      "Time step: 100 time 76.56545376777649\n",
      "Time step: 200 time 154.34795832633972\n",
      "Time step: 300 time 231.30416107177734\n",
      "Time step: 40, time 234.27225995063782\n",
      "Time step: 80, time 236.47673511505127\n",
      "Time step: 120, time 238.55442094802856\n",
      "[3.0052290144005642, 2.9231605124035376, 2.867187013790351, 2.877562962365891, 2.8844083229661277, 2.926580051170401, 2.9703120121446513]\n",
      "Time step: 100 time 86.58435559272766\n",
      "Time step: 200 time 178.8647096157074\n",
      "Time step: 300 time 273.9653203487396\n",
      "Time step: 40, time 277.54899191856384\n",
      "Time step: 80, time 279.90102648735046\n",
      "Time step: 120, time 282.57306385040283\n",
      "[3.0052290144005642, 2.9231605124035376, 2.867187013790351, 2.877562962365891, 2.8844083229661277, 2.926580051170401, 2.9703120121446513, 3.0309029966251484]\n",
      "Time step: 100 time 89.625235080719\n",
      "Time step: 200 time 187.3660488128662\n",
      "Time step: 300 time 308.56878900527954\n",
      "Time step: 40, time 312.77279257774353\n",
      "Time step: 80, time 315.58466601371765\n",
      "Time step: 120, time 318.6464886665344\n",
      "[3.0052290144005642, 2.9231605124035376, 2.867187013790351, 2.877562962365891, 2.8844083229661277, 2.926580051170401, 2.9703120121446513, 3.0309029966251484, 3.0238084533658776]\n",
      "best_weight is 3000\n"
     ]
    }
   ],
   "source": [
    "multi_steps = 1\n",
    "pred_time_steps = 36 * 4 + (multi_steps - 1)\n",
    "train_data = data[:, train_idx]\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "d = time_lags.shape[0]\n",
    "maxiter = 300\n",
    "eta = 0.03\n",
    "rank = 40\n",
    "rmse_list = []\n",
    "weights = range(1000, 10000, 1000)\n",
    "reset_random_seeds(1)\n",
    "for weight in weights:\n",
    "    lambda_w = weight\n",
    "    lambda_x = weight\n",
    "    lambda_theta = weight\n",
    "    results = st_prediction(train_data, time_lags, lambda_w, lambda_x, lambda_theta,\n",
    "                            eta, rank, pred_time_steps, maxiter, multi_steps, display=100)\n",
    "    rmse_list.append(RMSE(train_data[:, -36 * 4:], results[1]))\n",
    "    print(rmse_list)\n",
    "\n",
    "best_weight = weights[np.argmin(rmse_list)]\n",
    "print('best_weight is {}'.format(best_weight))  # was 3000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune rank"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step: 100 time 59.36144161224365\n",
      "Time step: 200 time 119.14671015739441\n",
      "Time step: 300 time 179.3572609424591\n",
      "Time step: 40, time 180.70070719718933\n",
      "Time step: 80, time 181.64855217933655\n",
      "Time step: 120, time 182.59422874450684\n",
      "[2.8717235320912806]\n",
      "Time step: 100 time 68.70429921150208\n",
      "Time step: 200 time 138.67472863197327\n",
      "Time step: 300 time 208.43986248970032\n",
      "Time step: 40, time 210.33303141593933\n",
      "Time step: 80, time 211.3952956199646\n",
      "Time step: 120, time 212.53566813468933\n",
      "[2.8717235320912806, 2.862204449291198]\n",
      "Time step: 100 time 77.98514008522034\n",
      "Time step: 200 time 155.91173601150513\n",
      "Time step: 300 time 234.240008354187\n",
      "Time step: 40, time 236.6175708770752\n",
      "Time step: 80, time 238.38280320167542\n",
      "Time step: 120, time 239.91370820999146\n",
      "[2.8717235320912806, 2.862204449291198, 2.8817985289484516]\n",
      "Time step: 100 time 105.11379528045654\n",
      "Time step: 200 time 211.31941318511963\n",
      "Time step: 300 time 317.82301902770996\n",
      "Time step: 40, time 321.0566785335541\n",
      "Time step: 80, time 323.2749378681183\n",
      "Time step: 120, time 325.621253490448\n",
      "[2.8717235320912806, 2.862204449291198, 2.8817985289484516, 2.852134576648217]\n",
      "Time step: 100 time 116.68876361846924\n",
      "Time step: 200 time 232.13970041275024\n",
      "Time step: 300 time 347.39221024513245\n",
      "Time step: 40, time 351.53191661834717\n",
      "Time step: 80, time 354.4843864440918\n",
      "Time step: 120, time 357.29869961738586\n",
      "[2.8717235320912806, 2.862204449291198, 2.8817985289484516, 2.852134576648217, 2.8680532325208254]\n",
      "Time step: 100 time 129.16001796722412\n",
      "Time step: 200 time 261.4625358581543\n",
      "Time step: 300 time 392.788875579834\n",
      "Time step: 40, time 397.6661913394928\n",
      "Time step: 80, time 401.27476358413696\n",
      "Time step: 120, time 405.0551726818085\n",
      "[2.8717235320912806, 2.862204449291198, 2.8817985289484516, 2.852134576648217, 2.8680532325208254, 2.8688974398741456]\n",
      "Time step: 100 time 147.01382637023926\n",
      "Time step: 200 time 296.29475831985474\n",
      "Time step: 300 time 444.95560002326965\n",
      "Time step: 40, time 450.97240805625916\n",
      "Time step: 80, time 455.5338969230652\n",
      "Time step: 120, time 460.1757900714874\n",
      "[2.8717235320912806, 2.862204449291198, 2.8817985289484516, 2.852134576648217, 2.8680532325208254, 2.8688974398741456, 2.8538893891904693]\n",
      "Time step: 100 time 165.22801446914673\n",
      "Time step: 200 time 331.8093202114105\n",
      "Time step: 300 time 496.1622176170349\n",
      "Time step: 40, time 503.34811449050903\n",
      "Time step: 80, time 509.0062539577484\n",
      "Time step: 120, time 514.6950941085815\n",
      "[2.8717235320912806, 2.862204449291198, 2.8817985289484516, 2.852134576648217, 2.8680532325208254, 2.8688974398741456, 2.8538893891904693, 2.862272408334345]\n",
      "Time step: 100 time 178.86491870880127\n",
      "Time step: 200 time 361.4007306098938\n",
      "Time step: 300 time 542.2478036880493\n",
      "Time step: 40, time 550.3734381198883\n",
      "Time step: 80, time 557.0779974460602\n",
      "Time step: 120, time 563.6077799797058\n",
      "[2.8717235320912806, 2.862204449291198, 2.8817985289484516, 2.852134576648217, 2.8680532325208254, 2.8688974398741456, 2.8538893891904693, 2.862272408334345, 2.852197062016129]\n",
      "best_rank is 35\n"
     ]
    }
   ],
   "source": [
    "lambda_w = best_weight\n",
    "lambda_x = best_weight\n",
    "lambda_theta = best_weight\n",
    "rmse_list = []\n",
    "ranks = range(20, 65, 5)\n",
    "reset_random_seeds(1)\n",
    "for rank in ranks:\n",
    "    results = st_prediction(train_data, time_lags, lambda_w, lambda_x, lambda_theta,\n",
    "                            eta, rank, pred_time_steps, maxiter, multi_steps)\n",
    "    rmse_list.append(RMSE(train_data[:, -36 * 4:], results[1]))\n",
    "    print(rmse_list)\n",
    "\n",
    "best_rank = ranks[np.argmin(rmse_list)]\n",
    "print(\"best_rank is {}\".format(best_rank))  # was 35"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Forcast and save results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step: 100 time 121.41348910331726\n",
      "Time step: 200 time 244.27593517303467\n",
      "Time step: 300 time 368.3721342086792\n",
      "Time step: 40, time 372.0929684638977\n",
      "Time step: 80, time 374.3268518447876\n",
      "Time step: 120, time 376.6232120990753\n",
      "Time step: 160, time 378.82584285736084\n",
      "3.7955850349910967\n",
      "4.282109640092683\n",
      "4.850035345958773\n",
      "Results of 1-step forecasting:\n",
      "RMSE of OD: 3.7955850349910967\n",
      "WMAPE of OD: 0.3425860171650234\n",
      "SMAPE of OD: 1.0086288815059803\n",
      "MAE of OD: 1.8406459745940205\n",
      "r2 of OD: 0.9158151772082446\n",
      "\n",
      "\n",
      "RMSE of flow: 70.19953155517578\n",
      "WMAPE of flow: 0.09900061786174774\n",
      "SMAPE of flow: 0.04952661693096161\n",
      "MAE of flow: 42.55283737182617\n",
      "r2 of flow: 0.9792202572747797\n",
      "Results of 2-step forecasting:\n",
      "RMSE of OD: 4.282109640092683\n",
      "WMAPE of OD: 0.3802070686893558\n",
      "SMAPE of OD: 0.824451725123523\n",
      "MAE of OD: 2.0427763406296555\n",
      "r2 of OD: 0.8928500638751655\n",
      "\n",
      "\n",
      "RMSE of flow: 105.82966613769531\n",
      "WMAPE of flow: 0.14904947578907013\n",
      "SMAPE of flow: 0.17815051972866058\n",
      "MAE of flow: 64.06503295898438\n",
      "r2 of flow: 0.9527734078139269\n",
      "Results of 3-step forecasting:\n",
      "RMSE of OD: 4.850035345958773\n",
      "WMAPE of OD: 0.42226457524101596\n",
      "SMAPE of OD: 0.8589917259689577\n",
      "MAE of OD: 2.2687428899254645\n",
      "r2 of OD: 0.8625432225526788\n",
      "\n",
      "\n",
      "RMSE of flow: 137.97030639648438\n",
      "WMAPE of flow: 0.19604481756687164\n",
      "SMAPE of flow: 0.5527913570404053\n",
      "MAE of flow: 84.26475524902344\n",
      "r2 of flow: 0.9197319136301246\n"
     ]
    }
   ],
   "source": [
    "multi_steps = 3\n",
    "pred_time_steps = 36 * 5 + (multi_steps - 1)\n",
    "train_data = data\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "rank = best_rank\n",
    "lambda_w = best_weight\n",
    "lambda_x = best_weight\n",
    "lambda_theta = best_weight\n",
    "eta = 0.03\n",
    "\n",
    "maxiter = 300\n",
    "reset_random_seeds(1)\n",
    "results = st_prediction(train_data, time_lags, lambda_w, lambda_x, lambda_theta,\n",
    "                        eta, rank, pred_time_steps, maxiter, multi_steps)\n",
    "\n",
    "for step in range(3):\n",
    "    print(RMSE(data[:, -180:], results[step + 1][:, 2 - step:2 - step + 180]))\n",
    "\n",
    "mat_hat1 = results[1][:, 2:2 + 180].copy()\n",
    "mat_hat2 = results[2][:, 1:1 + 180].copy()\n",
    "mat_hat3 = results[3][:, 0:0 + 180].copy()\n",
    "for i in range(mat_hat1.shape[1]):\n",
    "    mat_hat1[:, i] += data_mean[:, i % 36]\n",
    "    mat_hat2[:, i] += data_mean[:, i % 36]\n",
    "    mat_hat3[:, i] += data_mean[:, i % 36]\n",
    "\n",
    "real_OD = data0[:, -180:]\n",
    "real_flow = od2flow(real_OD, num_s=80)\n",
    "print('Results of 1-step forecasting:')\n",
    "predict_flow1 = od2flow(mat_hat1, num_s=80)\n",
    "get_score(real_OD, mat_hat1, real_flow, predict_flow1)\n",
    "\n",
    "print('Results of 2-step forecasting:')\n",
    "predict_flow2 = od2flow(mat_hat2, num_s=80)\n",
    "get_score(real_OD, mat_hat2, real_flow, predict_flow2)\n",
    "\n",
    "print('Results of 3-step forecasting:')\n",
    "predict_flow3 = od2flow(mat_hat3, num_s=80)\n",
    "get_score(real_OD, mat_hat3, real_flow, predict_flow3)\n",
    "\n",
    "np.savez_compressed('..//data//Hangzhou_OD_TRMF_step1.npz', data=mat_hat1)\n",
    "np.savez_compressed('..//data//Hangzhou_OD_TRMF_step2.npz', data=mat_hat2)\n",
    "np.savez_compressed('..//data//Hangzhou_OD_TRMF_step3.npz', data=mat_hat3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}