{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Temporal regularized matrix factorization (TRMF) for metro OD forecasting. Code is adapted from [https://github.com/xinychen/transdim](https://github.com/xinychen/transdim)\n",
    "\n",
    "Original paper for TRMF:\n",
    "- Hsiang-Fu Yu, Nikhil Rao, Inderjit S. Dhillon, 2016. Temporal regularized matrix factorization for high-dimensional time series prediction. 30th Conference on Neural Information Processing Systems (NIPS 2016),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from numpy.linalg import inv as inv\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def reset_random_seeds(n=1):\n",
    "    os.environ['PYTHONHASHSEED'] = str(n)\n",
    "    np.random.seed(n)\n",
    "    random.seed(n)\n",
    "\n",
    "def ar4cast(theta, X, time_lags, multi_step):\n",
    "    dim, rank = X.shape\n",
    "    d = time_lags.shape[0]\n",
    "    X_new = np.append(X, np.zeros((multi_step, rank)), axis = 0)\n",
    "    for t in range(multi_step):\n",
    "        X_new[dim + t, :] = np.einsum('kr, kr -> r', theta, X_new[dim + t - time_lags, :])\n",
    "    return X_new\n",
    "\n",
    "def TRMF(dense_mat, sparse_mat, init_para, init_hyper, time_lags, maxiter):\n",
    "    \"\"\"Temporal Regularized Matrix Factorization, TRMF.\"\"\"\n",
    "\n",
    "    ## Initialize parameters\n",
    "    W = init_para[\"W\"]\n",
    "    X = init_para[\"X\"]\n",
    "    theta = init_para[\"theta\"]\n",
    "\n",
    "    ## Set hyperparameters\n",
    "    lambda_w = init_hyper[\"lambda_w\"]\n",
    "    lambda_x = init_hyper[\"lambda_x\"]\n",
    "    lambda_theta = init_hyper[\"lambda_theta\"]\n",
    "    eta = init_hyper[\"eta\"]\n",
    "\n",
    "    dim1, dim2 = sparse_mat.shape\n",
    "    pos_train = np.where(sparse_mat != 0)\n",
    "    pos_test = np.where((dense_mat != 0) & (sparse_mat == 0))\n",
    "    binary_mat = sparse_mat.copy()\n",
    "    binary_mat[pos_train] = 1\n",
    "    d, rank = theta.shape\n",
    "\n",
    "    for it in range(maxiter):\n",
    "        ## Update spatial matrix W\n",
    "        for i in range(dim1):\n",
    "            pos0 = np.where(sparse_mat[i, :] != 0)\n",
    "            Xt = X[pos0[0], :]\n",
    "            vec0 = Xt.T @ sparse_mat[i, pos0[0]]\n",
    "            mat0 = inv(Xt.T @ Xt + lambda_w * np.eye(rank))\n",
    "            W[i, :] = mat0 @ vec0\n",
    "        ## Update temporal matrix X\n",
    "        for t in range(dim2):\n",
    "            pos0 = np.where(sparse_mat[:, t] != 0)\n",
    "            Wt = W[pos0[0], :]\n",
    "            Mt = np.zeros((rank, rank))\n",
    "            Nt = np.zeros(rank)\n",
    "            if t < np.max(time_lags):\n",
    "                Pt = np.zeros((rank, rank))\n",
    "                Qt = np.zeros(rank)\n",
    "            else:\n",
    "                Pt = np.eye(rank)\n",
    "                Qt = np.einsum('ij, ij -> j', theta, X[t - time_lags, :])\n",
    "            if t < dim2 - np.min(time_lags):\n",
    "                if t >= np.max(time_lags) and t < dim2 - np.max(time_lags):\n",
    "                    index = list(range(0, d))\n",
    "                else:\n",
    "                    index = list(np.where((t + time_lags >= np.max(time_lags)) & (t + time_lags < dim2)))[0]\n",
    "                for k in index:\n",
    "                    Ak = theta[k, :]\n",
    "                    Mt += np.diag(Ak ** 2)\n",
    "                    theta0 = theta.copy()\n",
    "                    theta0[k, :] = 0\n",
    "                    Nt += np.multiply(Ak, X[t + time_lags[k], :]\n",
    "                                      - np.einsum('ij, ij -> j', theta0, X[t + time_lags[k] - time_lags, :]))\n",
    "            vec0 = Wt.T @ sparse_mat[pos0[0], t] + lambda_x * Nt + lambda_x * Qt\n",
    "            mat0 = inv(Wt.T @ Wt + lambda_x * Mt + lambda_x * Pt + lambda_x * eta * np.eye(rank))\n",
    "            X[t, :] = mat0 @ vec0\n",
    "        ## Update AR coefficients theta\n",
    "        for k in range(d):\n",
    "            theta0 = theta.copy()\n",
    "            theta0[k, :] = 0\n",
    "            mat0 = np.zeros((dim2 - np.max(time_lags), rank))\n",
    "            for L in range(d):\n",
    "                mat0 += X[np.max(time_lags) - time_lags[L] : dim2 - time_lags[L] , :] @ np.diag(theta0[L, :])\n",
    "            VarPi = X[np.max(time_lags) : dim2, :] - mat0\n",
    "            var1 = np.zeros((rank, rank))\n",
    "            var2 = np.zeros(rank)\n",
    "            for t in range(np.max(time_lags), dim2):\n",
    "                B = X[t - time_lags[k], :]\n",
    "                var1 += np.diag(np.multiply(B, B))\n",
    "                var2 += np.diag(B) @ VarPi[t - np.max(time_lags), :]\n",
    "            theta[k, :] = inv(var1 + lambda_theta * np.eye(rank) / lambda_x) @ var2\n",
    "\n",
    "        X_new = ar4cast(theta, X, time_lags, multi_step)\n",
    "        mat_new = W @ X_new[- multi_step :, :].T\n",
    "        mat_hat = W @ X.T\n",
    "    mat_hat = np.append(mat_hat, mat_new, axis = 1)\n",
    "\n",
    "    return mat_hat, W, X_new, theta\n",
    "\n",
    "\n",
    "def update_x_partial(sparse_mat, W, X, theta, lambda_x, eta, time_lags, back_step):\n",
    "    d = time_lags.shape[0]\n",
    "    dim2, rank = X.shape\n",
    "    tmax = np.max(time_lags)\n",
    "    for t in range(dim2 - back_step, dim2):\n",
    "        pos0 = np.where(sparse_mat[:, t] != 0)\n",
    "        Wt = W[pos0[0], :]\n",
    "        Mt = np.zeros((rank, rank))\n",
    "        Nt = np.zeros(rank)\n",
    "        if t < tmax:\n",
    "            Pt = np.zeros((rank, rank))\n",
    "            Qt = np.zeros(rank)\n",
    "        else:\n",
    "            Pt = np.eye(rank)\n",
    "            Qt = np.einsum('ij, ij -> j', theta, X[t - time_lags, :])\n",
    "        if t < dim2 - np.min(time_lags):\n",
    "            if t >= tmax and t < dim2 - tmax:\n",
    "                index = list(range(0, d))\n",
    "            else:\n",
    "                index = list(np.where((t + time_lags >= tmax) & (t + time_lags < dim2)))[0]\n",
    "            for k in index:\n",
    "                Ak = theta[k, :]\n",
    "                Mt += np.diag(Ak ** 2)\n",
    "                theta0 = theta.copy()\n",
    "                theta0[k, :] = 0\n",
    "                Nt += np.multiply(Ak, X[t + time_lags[k], :]\n",
    "                                  - np.einsum('ij, ij -> j', theta0, X[t + time_lags[k] - time_lags, :]))\n",
    "        vec0 = Wt.T @ sparse_mat[pos0[0], t] + lambda_x * Nt + lambda_x * Qt\n",
    "        mat0 = inv(Wt.T @ Wt + lambda_x * Mt + lambda_x * Pt + lambda_x * eta * np.eye(rank))\n",
    "        X[t, :] = mat0 @ vec0\n",
    "    return X\n",
    "\n",
    "\n",
    "def TRMF_partial(dense_mat, sparse_mat, init_para, init_hyper, time_lags, maxiter):\n",
    "    ## Initialize parameters\n",
    "    W = init_para[\"W\"]\n",
    "    X = init_para[\"X\"]\n",
    "    theta = init_para[\"theta\"]\n",
    "    ## Set hyperparameters\n",
    "    lambda_x = init_hyper[\"lambda_x\"]\n",
    "    eta = init_hyper[\"eta\"]\n",
    "    back_step = 10 * multi_step\n",
    "    for it in range(maxiter):\n",
    "        X = update_x_partial(sparse_mat, W, X, theta, lambda_x, eta, time_lags, back_step)\n",
    "    X_new = ar4cast(theta, X, time_lags, multi_step)\n",
    "    mat_hat = W @ X_new[- multi_step :, :].T\n",
    "    mat_hat[mat_hat < 0] = 0\n",
    "\n",
    "    return mat_hat, W, X_new, theta\n",
    "\n",
    "\n",
    "def TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter, maxiter2=10):\n",
    "    dim1, T = dense_mat.shape\n",
    "    d = time_lags.shape[0]\n",
    "    start_time = T - pred_step\n",
    "    results = {step + 1: np.zeros((dim1, pred_time_steps)) for step in range(multi_step)}\n",
    "    for t in range(pred_time_steps):\n",
    "        if t == 0:\n",
    "            init_para = {\"W\": 0.1 * np.random.randn(dim1, rank),\n",
    "                         \"X\": 0.1 * np.random.randn(start_time, rank),\n",
    "                         \"theta\": 0.1 * np.random.randn(d, rank)}\n",
    "            mat, W, X_new, theta = TRMF(dense_mat[:, 0 : start_time], sparse_mat[:, 0 : start_time],\n",
    "                                        init_para, init_hyper, time_lags, maxiter)\n",
    "            X_new = X_new[0: (start_time + t), :]\n",
    "        else:\n",
    "            init_para = {\"W\": W, \"X\": X_new, \"theta\": theta}\n",
    "            mat, W, X_new, theta = TRMF_partial(dense_mat[:, 0 : start_time + t],\n",
    "                                                sparse_mat[:, 0 : start_time + t],\n",
    "                                                init_para, init_hyper, time_lags, maxiter2)\n",
    "            X_new = X_new[0: (start_time + t), :]\n",
    "        for step in range(multi_step):\n",
    "            results[step+1][:, t] = mat[:, -multi_step+step]\n",
    "\n",
    "        if (t + 1) % 36 == 0:\n",
    "            print('Time step: {}'.format(t + 1))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data0 = loadmat('..//data//Hangzhou_OD.mat')\n",
    "data0 = data0['OD']\n",
    "data0 = remove_weekends(data0, start=1)\n",
    "\n",
    "train_idx = np.arange(0, 36 * 14)\n",
    "test_idx = np.arange(36 * 14, 36 * 19)\n",
    "num_s = 80\n",
    "\n",
    "# Subtract the mean in the training set\n",
    "data = data0.astype(np.float64)\n",
    "data_mean = data[:, train_idx].reshape([num_s * num_s, 36, -1], order='F')\n",
    "data_mean = data_mean.mean(axis=2)\n",
    "for i in range(19):\n",
    "    data[:, i * 36:(i + 1) * 36] = data[:, i * 36:(i + 1) * 36] - data_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Parameter tuning\n",
    "## Tune weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=100, time=284.8777244091034\n",
      "[2.9905920867598628]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=300, time=562.4224574565887\n",
      "[2.9905920867598628, 2.9726288993595706]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=500, time=839.296044588089\n",
      "[2.9905920867598628, 2.9726288993595706, 2.9655605801566196]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=1000, time=1116.9267058372498\n",
      "[2.9905920867598628, 2.9726288993595706, 2.9655605801566196, 2.984341106994974]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=1500, time=1395.1043837070465\n",
      "[2.9905920867598628, 2.9726288993595706, 2.9655605801566196, 2.984341106994974, 3.002234674724591]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=2000, time=1672.5508267879486\n",
      "[2.9905920867598628, 2.9726288993595706, 2.9655605801566196, 2.984341106994974, 3.002234674724591, 3.0323108519909576]\n",
      "best_weight is 500\n"
     ]
    }
   ],
   "source": [
    "multi_step = 1\n",
    "pred_time_steps = 36 * 4 + (multi_step - 1)\n",
    "train_data = data[:, train_idx]\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "d = time_lags.shape[0]\n",
    "maxiter = 200\n",
    "eta = 0.03\n",
    "rank = 40\n",
    "rmse_list = []\n",
    "weights = [100, 300, 500, 1000, 1500, 2000]\n",
    "start = time.time()\n",
    "reset_random_seeds(1)\n",
    "for weight in weights:\n",
    "    init_hyper = {\"lambda_w\": weight, \"lambda_x\": weight, \"lambda_theta\": weight, \"eta\": eta}\n",
    "    results = TRMF_forecast(train_data, train_data, init_hyper, pred_time_steps, multi_step, rank, time_lags, maxiter, maxiter2=10)\n",
    "    rmse_list.append(RMSE(train_data[:, -36 * 4:], results[1]))\n",
    "    print('weight={}, time={}'.format(weight, time.time()-start))\n",
    "    print(rmse_list)\n",
    "\n",
    "best_weight = weights[np.argmin(rmse_list)]\n",
    "print('best_weight is {}'.format(best_weight))  # was 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tune rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=30, time=1905.2663311958313\n",
      "[2.9710703583901883]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=40, time=2181.7428998947144\n",
      "[2.9710703583901883, 2.9737112651901327]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=50, time=2527.1248364448547\n",
      "[2.9710703583901883, 2.9737112651901327, 2.958622635906084]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=60, time=2909.6129755973816\n",
      "[2.9710703583901883, 2.9737112651901327, 2.958622635906084, 2.963583845229799]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=70, time=3364.78337430954\n",
      "[2.9710703583901883, 2.9737112651901327, 2.958622635906084, 2.963583845229799, 2.959423582170035]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=80, time=3865.000997066498\n",
      "[2.9710703583901883, 2.9737112651901327, 2.958622635906084, 2.963583845229799, 2.959423582170035, 2.9607592797422684]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=90, time=4439.173535823822\n",
      "[2.9710703583901883, 2.9737112651901327, 2.958622635906084, 2.963583845229799, 2.959423582170035, 2.9607592797422684, 2.95532748224344]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=100, time=5081.179944753647\n",
      "[2.9710703583901883, 2.9737112651901327, 2.958622635906084, 2.963583845229799, 2.959423582170035, 2.9607592797422684, 2.95532748224344, 2.9559324038003805]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=110, time=5801.9595947265625\n",
      "[2.9710703583901883, 2.9737112651901327, 2.958622635906084, 2.963583845229799, 2.959423582170035, 2.9607592797422684, 2.95532748224344, 2.9559324038003805, 2.960236187357405]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=120, time=6585.034026145935\n",
      "[2.9710703583901883, 2.9737112651901327, 2.958622635906084, 2.963583845229799, 2.959423582170035, 2.9607592797422684, 2.95532748224344, 2.9559324038003805, 2.960236187357405, 2.955317097467935]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=130, time=7469.1608419418335\n",
      "[2.9710703583901883, 2.9737112651901327, 2.958622635906084, 2.963583845229799, 2.959423582170035, 2.9607592797422684, 2.95532748224344, 2.9559324038003805, 2.960236187357405, 2.955317097467935, 2.956807202878523]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "weight=140, time=8423.449007749557\n",
      "[2.9710703583901883, 2.9737112651901327, 2.958622635906084, 2.963583845229799, 2.959423582170035, 2.9607592797422684, 2.95532748224344, 2.9559324038003805, 2.960236187357405, 2.955317097467935, 2.956807202878523, 2.9568929309258647]\n",
      "best_rank is 120\n"
     ]
    }
   ],
   "source": [
    "init_hyper = {\"lambda_w\": best_weight, \"lambda_x\": best_weight, \"lambda_theta\": best_weight, \"eta\": eta}\n",
    "rmse_list = []\n",
    "ranks = range(30, 150, 10)\n",
    "reset_random_seeds(1)\n",
    "for rank in ranks:\n",
    "    results = TRMF_forecast(train_data, train_data, init_hyper, pred_time_steps, multi_step, rank, time_lags, maxiter, maxiter2=10)\n",
    "    rmse_list.append(RMSE(train_data[:, -36 * 4:], results[1]))\n",
    "    print('weight={}, time={}'.format(rank, time.time()-start))\n",
    "    print(rmse_list)\n",
    "\n",
    "best_rank = ranks[np.argmin(rmse_list)]\n",
    "print(\"best_rank is {}\".format(best_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Forcast and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "3.801086821059394\n",
      "3.886189916865785\n",
      "3.9638353646522995\n",
      "Results of 1-step forecasting:\n",
      "RMSE of OD: 3.8010868210593944\n",
      "WMAPE of OD: 0.34021980655924294\n",
      "SMAPE of OD: 0.9612498400012086\n",
      "MAE of OD: 1.8279327994836847\n",
      "r2 of OD: 0.9155709447295383\n",
      "\n",
      "\n",
      "RMSE of flow: 77.69996643066406\n",
      "WMAPE of flow: 0.0999877080321312\n",
      "SMAPE of flow: 0.16383419930934906\n",
      "MAE of flow: 42.97711181640625\n",
      "r2 of flow: 0.974542640705724\n",
      "Results of 2-step forecasting:\n",
      "RMSE of OD: 3.886189916865785\n",
      "WMAPE of OD: 0.344813842786603\n",
      "SMAPE of OD: 0.9622279913999333\n",
      "MAE of OD: 1.8526156349333174\n",
      "r2 of OD: 0.9117480333971929\n",
      "\n",
      "\n",
      "RMSE of flow: 81.19125366210938\n",
      "WMAPE of flow: 0.10545614361763\n",
      "SMAPE of flow: 0.17583689093589783\n",
      "MAE of flow: 45.327579498291016\n",
      "r2 of flow: 0.9722034937739886\n",
      "Results of 3-step forecasting:\n",
      "RMSE of OD: 3.963835364652299\n",
      "WMAPE of OD: 0.34824376961485337\n",
      "SMAPE of OD: 0.9626348763133519\n",
      "MAE of OD: 1.8710439440097208\n",
      "r2 of OD: 0.9081862836261226\n",
      "\n",
      "\n",
      "RMSE of flow: 83.11664581298828\n",
      "WMAPE of flow: 0.10806084424257278\n",
      "SMAPE of flow: 0.17244526743888855\n",
      "MAE of flow: 46.447139739990234\n",
      "r2 of flow: 0.9708695143911686\n"
     ]
    }
   ],
   "source": [
    "best_weight = best_weight\n",
    "best_rank = best_rank\n",
    "multi_step = 3\n",
    "pred_time_steps = 36 * 5 + (multi_step - 1)\n",
    "train_data = data\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "rank = best_rank\n",
    "lambda_w = best_weight\n",
    "lambda_x = best_weight\n",
    "lambda_theta = best_weight\n",
    "eta = 0.03\n",
    "maxiter = 200\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "reset_random_seeds(1)\n",
    "\n",
    "# def TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter):\n",
    "results = TRMF_forecast(train_data, train_data, init_hyper, pred_time_steps, multi_step, best_rank, time_lags, maxiter, maxiter2=10)\n",
    "\n",
    "for step in range(3):\n",
    "    print(RMSE(data[:, -180:], results[step + 1][:, 2 - step:2 - step + 180]))\n",
    "\n",
    "mat_hat1 = results[1][:, 2:2 + 180].copy()\n",
    "mat_hat2 = results[2][:, 1:1 + 180].copy()\n",
    "mat_hat3 = results[3][:, 0:0 + 180].copy()\n",
    "for i in range(mat_hat1.shape[1]):\n",
    "    mat_hat1[:, i] += data_mean[:, i % 36]\n",
    "    mat_hat2[:, i] += data_mean[:, i % 36]\n",
    "    mat_hat3[:, i] += data_mean[:, i % 36]\n",
    "\n",
    "real_OD = data0[:, -180:]\n",
    "real_flow = od2flow(real_OD, num_s=80)\n",
    "print('Results of 1-step forecasting:')\n",
    "predict_flow1 = od2flow(mat_hat1, num_s=80)\n",
    "get_score(real_OD, mat_hat1, real_flow, predict_flow1)\n",
    "\n",
    "print('Results of 2-step forecasting:')\n",
    "predict_flow2 = od2flow(mat_hat2, num_s=80)\n",
    "get_score(real_OD, mat_hat2, real_flow, predict_flow2)\n",
    "\n",
    "print('Results of 3-step forecasting:')\n",
    "predict_flow3 = od2flow(mat_hat3, num_s=80)\n",
    "get_score(real_OD, mat_hat3, real_flow, predict_flow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('..//data//Hangzhou_OD_TRMF_step1.npz', data=mat_hat1)\n",
    "np.savez_compressed('..//data//Hangzhou_OD_TRMF_step2.npz', data=mat_hat2)\n",
    "np.savez_compressed('..//data//Hangzhou_OD_TRMF_step3.npz', data=mat_hat3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
