{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36172,
     "status": "ok",
     "timestamp": 1631624933193,
     "user": {
      "displayName": "Transdata McGill",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18341276904046916116"
     },
     "user_tz": 240
    },
    "id": "hP1Vw220XMaL",
    "outputId": "f08de6bd-6a93-41cf-f6a5-6700f54e2788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "    raise SystemError('GPU device not found')\n",
    "\n",
    "def cpu():\n",
    "    with tf.device('/cpu:0'):\n",
    "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
    "    return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "def gpu():\n",
    "    with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "\n",
    "def reset_random_seeds(n=1):\n",
    "    os.environ['PYTHONHASHSEED']=str(n)\n",
    "    tf.random.set_seed(n)\n",
    "    np.random.seed(n)\n",
    "    random.seed(n)\n",
    "\n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()\n",
    "gpu()\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZXCbaZLXZrz"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import gc\n",
    "from sklearn.metrics import r2_score\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "def stagger_data(data, h):\n",
    "    \"\"\"|\n",
    "    >>> i = np.array([[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12]])\n",
    "    >>> stagger_data(i, [1, 3])\n",
    "    (array([[ 3,  4,  5],\n",
    "           [ 9, 10, 11],\n",
    "           [ 1,  2,  3],\n",
    "           [ 7,  8,  9]]), array([[ 4,  5,  6],\n",
    "           [10, 11, 12]]))\n",
    "    \"\"\"\n",
    "    h.sort()\n",
    "    len_h = len(h)\n",
    "    n, m = data.shape\n",
    "    max_h = max(h)\n",
    "\n",
    "    Y = data[:, max_h:]\n",
    "    X = np.zeros((n * len_h, m - max_h), dtype=data.dtype)\n",
    "    for i in range(len_h):\n",
    "        X[i * n: i * n + n, :] = data[:, max_h - h[i]:m - h[i]]\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def remove_weekends(data, start=0, bs=36):\n",
    "    _, m = data.shape\n",
    "    n_day = int(m / bs)\n",
    "    weekday = np.concatenate([np.arange(start, 7) % 7, np.arange(n_day) % 7])[:n_day]\n",
    "    weekday = np.repeat(weekday, bs)\n",
    "    return data[:, weekday < 5]\n",
    "\n",
    "\n",
    "def get_flow1(od, s, dir='o', num_s=159):\n",
    "    \"\"\"Get the flow of station `s`\"\"\"\n",
    "    n = od.shape[0]\n",
    "    if dir == 'o':\n",
    "        idx = np.arange(s, n, num_s)\n",
    "    elif dir == 'd':\n",
    "        idx = np.arange((s * num_s), (s * num_s + num_s))\n",
    "    return np.sum(od[idx, :], axis=0)\n",
    "\n",
    "\n",
    "def od2flow(od, s_list=None, dir='o', num_s=159):\n",
    "    if s_list is None:\n",
    "        s_list = range(num_s)\n",
    "\n",
    "    n_s = len(s_list)\n",
    "    flow = np.zeros((n_s, od.shape[1]), dtype=np.float32)\n",
    "    for i, s in enumerate(s_list):\n",
    "        flow[i, :] = get_flow1(od, s, dir, num_s)\n",
    "    return flow\n",
    "\n",
    "\n",
    "def RMSE(f0, f1, axis=None):\n",
    "    return np.sqrt(np.mean((f0 - f1) ** 2, axis))\n",
    "\n",
    "\n",
    "def SMAPE(real, predict):\n",
    "    a = real.ravel().copy()\n",
    "    b = predict.ravel().copy()\n",
    "    mask = ((a>0) & (b>0))\n",
    "    a = a[mask]\n",
    "    b = b[mask]\n",
    "    return 2*np.mean(np.abs(a-b)/(np.abs(a)+np.abs(b)))\n",
    "\n",
    "\n",
    "def WMAPE(real, predict):\n",
    "    e = np.sum(np.abs(real - predict))/np.sum(np.abs(real))\n",
    "    return e\n",
    "\n",
    "\n",
    "def MAE(real, predict):\n",
    "    return np.mean(np.abs(real - predict))\n",
    "\n",
    "def MSE(f0, f1, axis=None):\n",
    "    return np.mean((f0 - f1) ** 2, axis)\n",
    "\n",
    "\n",
    "def get_score(real, predict, real_flow, predict_flow):\n",
    "    print('RMSE of OD: {}'.format(RMSE(real, predict)))\n",
    "    print('WMAPE of OD: {}'.format(WMAPE(real, predict)))\n",
    "    print('SMAPE of OD: {}'.format(SMAPE(real, predict)))\n",
    "    print('MAE of OD: {}'.format(MAE(real, predict)))\n",
    "    print('r2 of OD: {}'.format(r2_score(real.ravel(), predict.ravel())))\n",
    "    print('\\n')\n",
    "    print('RMSE of flow: {}'.format(RMSE(real_flow, predict_flow)))\n",
    "    print('WMAPE of flow: {}'.format(WMAPE(real_flow, predict_flow)))\n",
    "    print('SMAPE of flow: {}'.format(SMAPE(real_flow, predict_flow)))\n",
    "    print('MAE of flow: {}'.format(MAE(real_flow, predict_flow)))\n",
    "    print('r2 of flow: {}'.format(r2_score(real_flow.ravel(), predict_flow.ravel())))\n",
    "\n",
    "def start_end_idx(start, end, weekend=False, night=False):\n",
    "    date = pd.period_range('2017-07-01', '2017-09-30 23:30', freq='30T')\n",
    "    date = date.to_timestamp()\n",
    "    if not night:\n",
    "        date = date[date.hour >= 6]\n",
    "    if not weekend:\n",
    "        date = date[date.weekday < 5]\n",
    "    idx = pd.DataFrame(data=np.arange(date.shape[0]), index=date)\n",
    "    return idx.loc[start:end, :].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KzTgYUw4Uez"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ts5me2dHS9JS"
   },
   "outputs": [],
   "source": [
    "data0 = loadmat('drive//MyDrive//data//OD_3m.mat')\n",
    "data0 = data0['OD']\n",
    "data0 = remove_weekends(data0, start=5)\n",
    "num_s=159\n",
    "\n",
    "# Subtract the mean of the training set\n",
    "data = data0.astype(np.float64)\n",
    "data_mean = data[:, 0:30*36].reshape([num_s*num_s, 36, -1], order='F')\n",
    "data_mean = data_mean.mean(axis=2)\n",
    "for i in range(65):\n",
    "    data[:,i*36:(i+1)*36] = data[:,i*36:(i+1)*36] - data_mean\n",
    "\n",
    "flow0 = od2flow(data)\n",
    "flow = np.zeros((flow0.shape[0]*2, flow0.shape[1]), dtype=flow0.dtype)\n",
    "flow[0:flow0.shape[0], :] = flow0\n",
    "flow[flow0.shape[0]:, 1:] = flow0[:, 0:-1]\n",
    "\n",
    "train_idx = start_end_idx('2017-07-03', '2017-08-11', weekend=False, night=False)\n",
    "test_idx = start_end_idx('2017-08-14', '2017-08-25', weekend=False, night=False)\n",
    "\n",
    "\n",
    "h = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "X_train, Y_train = stagger_data(data[:, train_idx], h)\n",
    "m_train = X_train.shape[1]\n",
    "X_train = np.concatenate([X_train, flow[:, train_idx][:, -m_train-1:-1]/159]).T\n",
    "Y_train = Y_train.T\n",
    "\n",
    "# Split training and validataion set\n",
    "reset_random_seeds(0)\n",
    "random_idx = np.random.permutation(m_train)\n",
    "train_idx = random_idx[0:int(np.floor(m_train*0.8))]\n",
    "validate_idx = random_idx[int(np.floor(m_train*0.8)):]\n",
    "x_train = X_train[train_idx, :]\n",
    "y_train = Y_train[train_idx, :]\n",
    "x_validate = X_train[validate_idx, :]\n",
    "y_validate = Y_train[validate_idx, :]\n",
    "\n",
    "\n",
    "X_test, Y_test = stagger_data(data[:, (test_idx[0]-max(h)):(test_idx[-1]+1)], h)\n",
    "X_test = np.concatenate([X_test, flow[:, test_idx-1]/num_s]).T\n",
    "Y_test = Y_test.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuWHNahF4b5f"
   },
   "source": [
    "# Select model order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RnJ5Jq5lf2_"
   },
   "outputs": [],
   "source": [
    "def create_net(n_input=num_s*num_s*10, n_hidden=50, activation=None):\n",
    "    seq = keras.Sequential(\n",
    "      [\n",
    "      layers.Dense(n_hidden, input_shape=(n_input,), \n",
    "                   activation=activation,\n",
    "                  #  kernel_regularizer=tf.keras.regularizers.L2(0.0001)\n",
    "                   ),\n",
    "      layers.Dense(num_s*num_s,\n",
    "                  #  kernel_regularizer=tf.keras.regularizers.L2(0.0001)\n",
    "                   )\n",
    "      ]\n",
    "    )\n",
    "    return seq\n",
    "\n",
    "call_back = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=20, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 843653,
     "status": "ok",
     "timestamp": 1631547939958,
     "user": {
      "displayName": "Zhanhong Cheng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghf9tjnpXtH8UqcRXabhSLJr8JznMk-NALJeT6E_g=s64",
      "userId": "09964432197138505126"
     },
     "user_tz": 240
    },
    "id": "q-38tw9yYtVW",
    "outputId": "ca59f8e5-2ba9-4738-9864-5de860e13cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation linear hidden_layers 10, val_loss 8.264047573660022, current best val_loss 8.264047573660022\n",
      "Activation linear hidden_layers 20, val_loss 8.255797261389617, current best val_loss 8.255797261389617\n",
      "Activation linear hidden_layers 30, val_loss 8.246760510952674, current best val_loss 8.246760510952674\n",
      "Activation linear hidden_layers 40, val_loss 8.301582403272112, current best val_loss 8.246760510952674\n",
      "Activation linear hidden_layers 50, val_loss 8.159299280041846, current best val_loss 8.159299280041846\n",
      "Activation linear hidden_layers 60, val_loss 8.223649773642281, current best val_loss 8.159299280041846\n",
      "Activation linear hidden_layers 70, val_loss 8.251460904272918, current best val_loss 8.159299280041846\n",
      "Activation linear hidden_layers 80, val_loss 8.349527933887233, current best val_loss 8.159299280041846\n",
      "Activation linear hidden_layers 90, val_loss 8.192551314273727, current best val_loss 8.159299280041846\n",
      "Activation linear hidden_layers 100, val_loss 8.405345025463639, current best val_loss 8.159299280041846\n",
      "Activation sigmoid hidden_layers 10, val_loss 8.554118709029439, current best val_loss 8.159299280041846\n",
      "Activation sigmoid hidden_layers 20, val_loss 8.528532861549163, current best val_loss 8.159299280041846\n",
      "Activation sigmoid hidden_layers 30, val_loss 8.479376516609548, current best val_loss 8.159299280041846\n",
      "Activation sigmoid hidden_layers 40, val_loss 8.464953355700056, current best val_loss 8.159299280041846\n",
      "Activation sigmoid hidden_layers 50, val_loss 8.450217964493225, current best val_loss 8.159299280041846\n",
      "Activation sigmoid hidden_layers 60, val_loss 8.436177552303421, current best val_loss 8.159299280041846\n",
      "Activation sigmoid hidden_layers 70, val_loss 8.42391820265868, current best val_loss 8.159299280041846\n",
      "Activation sigmoid hidden_layers 80, val_loss 8.423609653365947, current best val_loss 8.159299280041846\n",
      "Activation sigmoid hidden_layers 90, val_loss 8.42074782826076, current best val_loss 8.159299280041846\n",
      "Activation sigmoid hidden_layers 100, val_loss 8.424594081450845, current best val_loss 8.159299280041846\n",
      "Activation relu hidden_layers 10, val_loss 8.836069414548785, current best val_loss 8.159299280041846\n",
      "Activation relu hidden_layers 20, val_loss 9.424625334338607, current best val_loss 8.159299280041846\n",
      "Activation relu hidden_layers 30, val_loss 10.13885391092746, current best val_loss 8.159299280041846\n",
      "Activation relu hidden_layers 40, val_loss 10.612844262167672, current best val_loss 8.159299280041846\n",
      "Activation relu hidden_layers 50, val_loss 10.964211570882352, current best val_loss 8.159299280041846\n",
      "Activation relu hidden_layers 60, val_loss 11.218156645231158, current best val_loss 8.159299280041846\n",
      "Activation relu hidden_layers 70, val_loss 11.321800909309744, current best val_loss 8.159299280041846\n",
      "Activation relu hidden_layers 80, val_loss 11.505288195387225, current best val_loss 8.159299280041846\n",
      "Activation relu hidden_layers 90, val_loss 11.384728797128268, current best val_loss 8.159299280041846\n",
      "Activation relu hidden_layers 100, val_loss 11.537379077661818, current best val_loss 8.159299280041846\n"
     ]
    }
   ],
   "source": [
    "activation_list = ['linear', 'sigmoid', 'relu']\n",
    "n_hidden_list = np.linspace(10, 100, 10, dtype=np.int)\n",
    "best_e = 10000\n",
    "\n",
    "for activation in activation_list:\n",
    "    for n_hidden in n_hidden_list:\n",
    "        tf.keras.backend.clear_session()\n",
    "        reset_random_seeds(0)\n",
    "        seq = create_net(n_input=x_train.shape[1], n_hidden=n_hidden, activation=activation)\n",
    "        gc.collect()\n",
    "        seq.compile(loss=\"mean_squared_error\", optimizer=\"RMSprop\")\n",
    "        seq.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=32,\n",
    "            epochs=200,\n",
    "            verbose=0,\n",
    "            shuffle=True,\n",
    "            validation_data =(x_validate, y_validate),\n",
    "            callbacks=[call_back],\n",
    "        )\n",
    "        val_loss = min(seq.history.history['val_loss'])\n",
    "\n",
    "        if val_loss < best_e:\n",
    "            best_e = val_loss\n",
    "            best_model = seq\n",
    "        print('Activation {} hidden_layers {}, val_loss {}, current best val_loss {}'.format(activation, n_hidden, val_loss, best_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55717,
     "status": "ok",
     "timestamp": 1631625005928,
     "user": {
      "displayName": "Transdata McGill",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18341276904046916116"
     },
     "user_tz": 240
    },
    "id": "HBtAYNwxUxAY",
    "outputId": "59bb4211-3ae5-4659-f3c3-25a9af2ea466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.159299280041846\n"
     ]
    }
   ],
   "source": [
    "activation = 'linear'\n",
    "n_hidden = 50\n",
    "tf.keras.backend.clear_session()\n",
    "reset_random_seeds(0)\n",
    "seq = create_net(n_input=x_train.shape[1], n_hidden=n_hidden, activation=activation)\n",
    "gc.collect()\n",
    "seq.compile(loss=\"mean_squared_error\", optimizer=\"RMSprop\")\n",
    "seq.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=200,\n",
    "    verbose=0,\n",
    "    shuffle=True,\n",
    "    validation_data =(x_validate, y_validate),\n",
    "    callbacks=[call_back],\n",
    ")\n",
    "val_loss = min(seq.history.history['val_loss'])\n",
    "print(val_loss)\n",
    "best_model = seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8MsxO1f-sO4"
   },
   "source": [
    "# Multistep forecast for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VlwFgpsyqVrC"
   },
   "outputs": [],
   "source": [
    "# One-step forecast\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "seq = best_model\n",
    "X1 = np.concatenate([X_train[-36:, :], X_test], axis=0)\n",
    "predict_OD1 = seq.predict(X1)\n",
    "\n",
    "\n",
    "# Two-step forecast\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "n = data.shape[0]\n",
    "nh = len(h)\n",
    "X2 = np.concatenate([X_train[-36:, :], X_test])\n",
    "# Reuse one-step forecast OD\n",
    "X2[3:, 0:n] = predict_OD1[0:-3, :]\n",
    "# Reuse one-step forecast flow\n",
    "X2[3:, n*nh:n*nh+num_s] = od2flow(predict_OD1[2:-1, :].T, num_s=num_s).T/num_s\n",
    "predict_OD2 = seq.predict(X2)\n",
    "\n",
    "\n",
    "# Three-step forecast\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "X3 = np.concatenate([X_train[-36:, :], X_test])\n",
    "# Reuse one and two-step forecast OD\n",
    "X3[4:, 0:n] = predict_OD2[1:-3, :]\n",
    "X3[4:, n:2*n] = predict_OD1[0:-4, :]\n",
    "# Reuse one and two-step forecast flow\n",
    "X3[4:, n*nh:n*nh+num_s] = od2flow(predict_OD2[3:-1, :].T, num_s=num_s).T/num_s\n",
    "X3[4:, n*nh+num_s:] = od2flow(predict_OD1[2:-2, :].T, num_s=num_s).T/num_s\n",
    "predict_OD3 = seq.predict(X3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-4i8vG1Ecy6"
   },
   "source": [
    "# Add mean back and save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13791,
     "status": "ok",
     "timestamp": 1631625505014,
     "user": {
      "displayName": "Transdata McGill",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18341276904046916116"
     },
     "user_tz": 240
    },
    "id": "_Ij-DWpx9Bf4",
    "outputId": "3685b628-eb9f-4bcb-d714-e862450ebdfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The result of 1-step prediction: \n",
      "\n",
      "RMSE of OD: 3.148006579364526\n",
      "WMAPE of OD: 0.30232312723309146\n",
      "SMAPE of OD: 0.47943925644145785\n",
      "MAE of OD: 1.5362054581471392\n",
      "r2 of OD: 0.953803933306505\n",
      "\n",
      "\n",
      "RMSE of flow: 101.93280029296875\n",
      "WMAPE of flow: 0.06437187641859055\n",
      "SMAPE of flow: 0.10873428732156754\n",
      "MAE of flow: 52.00813293457031\n",
      "r2 of flow: 0.9890230134259884\n",
      "\n",
      " The result of 2-step prediction: \n",
      "\n",
      "RMSE of OD: 3.164442742385335\n",
      "WMAPE of OD: 0.3028294382371717\n",
      "SMAPE of OD: 0.4789922620810597\n",
      "MAE of OD: 1.538778194593426\n",
      "r2 of OD: 0.9533202823159788\n",
      "\n",
      "\n",
      "RMSE of flow: 104.00349426269531\n",
      "WMAPE of flow: 0.06575294584035873\n",
      "SMAPE of flow: 0.1105436235666275\n",
      "MAE of flow: 53.12394332885742\n",
      "r2 of flow: 0.988572503291121\n",
      "\n",
      " The result of 3-step prediction: \n",
      "\n",
      "RMSE of OD: 3.177593912996778\n",
      "WMAPE of OD: 0.30319735010262905\n",
      "SMAPE of OD: 0.4786637328058872\n",
      "MAE of OD: 1.540647678483082\n",
      "r2 of OD: 0.952931481742629\n",
      "\n",
      "\n",
      "RMSE of flow: 106.06350708007812\n",
      "WMAPE of flow: 0.066938117146492\n",
      "SMAPE of flow: 0.1124134212732315\n",
      "MAE of flow: 54.081478118896484\n",
      "r2 of flow: 0.9881153287829325\n"
     ]
    }
   ],
   "source": [
    "real_OD = data0[:, test_idx]\n",
    "real_flow = od2flow(real_OD, num_s=num_s)\n",
    "\n",
    "# Add mean values\n",
    "predict_OD1=predict_OD1[-360:, :].T\n",
    "for i in range(predict_OD1.shape[1]):\n",
    "    predict_OD1[:,i] += data_mean[:, i%36]\n",
    "predict_flow1 = od2flow(predict_OD1, num_s=num_s)\n",
    "print(\"\\n The result of 1-step prediction: \\n\")\n",
    "get_score(real_OD, predict_OD1, real_flow, predict_flow1)\n",
    "\n",
    "predict_OD2=predict_OD2[-360:, :].T\n",
    "for i in range(predict_OD2.shape[1]):\n",
    "    predict_OD2[:,i] += data_mean[:, i%36]\n",
    "predict_flow2 = od2flow(predict_OD2, num_s=num_s)\n",
    "print(\"\\n The result of 2-step prediction: \\n\")\n",
    "get_score(real_OD, predict_OD2, real_flow, predict_flow2)\n",
    "\n",
    "\n",
    "predict_OD3=predict_OD3[-360:, :].T\n",
    "for i in range(predict_OD3.shape[1]):\n",
    "    predict_OD3[:,i] += data_mean[:, i%36]\n",
    "predict_flow3 = od2flow(predict_OD3, num_s=num_s)\n",
    "print(\"\\n The result of 3-step prediction: \\n\")\n",
    "get_score(real_OD, predict_OD3, real_flow, predict_flow3)\n",
    "\n",
    "np.savez_compressed('/content/drive/MyDrive/data/Guangzhou_OD_FNN_step1.npz', data=predict_OD1)\n",
    "np.savez_compressed('/content/drive/MyDrive/data/Guangzhou_OD_FNN_step2.npz', data=predict_OD2)\n",
    "np.savez_compressed('/content/drive/MyDrive/data/Guangzhou_OD_FNN_step3.npz', data=predict_OD3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FNN_sub_mean_2boarding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
