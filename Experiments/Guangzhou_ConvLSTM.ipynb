{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wynKKyjGVCbY"
   },
   "source": [
    "# Import data and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hP1Vw220XMaL",
    "outputId": "8b1af329-db20-40c7-c0dc-d2a36ec216e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "    raise SystemError('GPU device not found')\n",
    "\n",
    "def cpu():\n",
    "    with tf.device('/cpu:0'):\n",
    "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
    "    return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "def gpu():\n",
    "    with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "\n",
    "def reset_random_seeds(n=1):\n",
    "    os.environ['PYTHONHASHSEED']=str(n)\n",
    "    tf.random.set_seed(n)\n",
    "    np.random.seed(n)\n",
    "    random.seed(n)\n",
    "\n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()\n",
    "gpu()\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZXCbaZLXZrz"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import gc\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "\n",
    "\n",
    "def stagger_data(data, h):\n",
    "    \"\"\"\n",
    "    >>> i = np.array([[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12]])\n",
    "    >>> stagger_data(i, [1, 3])\n",
    "    (array([[ 3,  4,  5],\n",
    "           [ 9, 10, 11],\n",
    "           [ 1,  2,  3],\n",
    "           [ 7,  8,  9]]), array([[ 4,  5,  6],\n",
    "           [10, 11, 12]]))\n",
    "    \"\"\"\n",
    "    h.sort()\n",
    "    len_h = len(h)\n",
    "    n, m = data.shape\n",
    "    max_h = max(h)\n",
    "\n",
    "    Y = data[:, max_h:]\n",
    "    X = np.zeros((n * len_h, m - max_h), dtype=data.dtype)\n",
    "    for i in range(len_h):\n",
    "        X[i * n: i * n + n, :] = data[:, max_h - h[i]:m - h[i]]\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def remove_weekends(data, start=0, bs=36):\n",
    "    _, m = data.shape\n",
    "    n_day = int(m / bs)\n",
    "    weekday = np.concatenate([np.arange(start, 7) % 7, np.arange(n_day) % 7])[:n_day]\n",
    "    weekday = np.repeat(weekday, bs)\n",
    "    return data[:, weekday < 5]\n",
    "\n",
    "\n",
    "def get_flow1(od, s, dir='o', num_s=159):\n",
    "    \"\"\"Get the flow of station `s`\"\"\"\n",
    "    n = od.shape[0]\n",
    "    if dir == 'o':\n",
    "        idx = np.arange(s, n, num_s)\n",
    "    elif dir == 'd':\n",
    "        idx = np.arange((s * num_s), (s * num_s + num_s))\n",
    "    return np.sum(od[idx, :], axis=0)\n",
    "\n",
    "\n",
    "def od2flow(od, s_list=None, dir='o', num_s=159):\n",
    "    if s_list is None:\n",
    "        s_list = range(num_s)\n",
    "\n",
    "    n_s = len(s_list)\n",
    "    flow = np.zeros((n_s, od.shape[1]), dtype=np.float32)\n",
    "    for i, s in enumerate(s_list):\n",
    "        flow[i, :] = get_flow1(od, s, dir, num_s)\n",
    "    return flow\n",
    "\n",
    "\n",
    "def RMSE(f0, f1, axis=None):\n",
    "    return np.sqrt(np.mean((f0 - f1) ** 2, axis))\n",
    "\n",
    "\n",
    "def SMAPE(real, predict):\n",
    "    a = real.ravel().copy()\n",
    "    b = predict.ravel().copy()\n",
    "    mask = ((a>0) & (b>0))\n",
    "    a = a[mask]\n",
    "    b = b[mask]\n",
    "    return 2*np.mean(np.abs(a-b)/(np.abs(a)+np.abs(b)))\n",
    "\n",
    "\n",
    "def WMAPE(real, predict):\n",
    "    e = np.sum(np.abs(real - predict))/np.sum(np.abs(real))\n",
    "    return e\n",
    "\n",
    "\n",
    "def MAE(real, predict):\n",
    "    return np.mean(np.abs(real - predict))\n",
    "\n",
    "def MSE(f0, f1, axis=None):\n",
    "    return np.mean((f0 - f1) ** 2, axis)\n",
    "\n",
    "\n",
    "def get_score(real, predict, real_flow, predict_flow):\n",
    "    print('RMSE of OD: {}'.format(RMSE(real, predict)))\n",
    "    print('WMAPE of OD: {}'.format(WMAPE(real, predict)))\n",
    "    print('SMAPE of OD: {}'.format(SMAPE(real, predict)))\n",
    "    print('MAE of OD: {}'.format(MAE(real, predict)))\n",
    "    print('r2 of OD: {}'.format(r2_score(real.ravel(), predict.ravel())))\n",
    "    print('\\n')\n",
    "    print('RMSE of flow: {}'.format(RMSE(real_flow, predict_flow)))\n",
    "    print('WMAPE of flow: {}'.format(WMAPE(real_flow, predict_flow)))\n",
    "    print('SMAPE of flow: {}'.format(SMAPE(real_flow, predict_flow)))\n",
    "    print('MAE of flow: {}'.format(MAE(real_flow, predict_flow)))\n",
    "    print('r2 of flow: {}'.format(r2_score(real_flow.ravel(), predict_flow.ravel())))\n",
    "\n",
    "\n",
    "def start_end_idx(start, end, weekend=False, night=False):\n",
    "    date = pd.period_range('2017-07-01', '2017-09-30 23:30', freq='30T')\n",
    "    date = date.to_timestamp()\n",
    "    if not night:\n",
    "        date = date[date.hour >= 6]\n",
    "    if not weekend:\n",
    "        date = date[date.weekday < 5]\n",
    "    idx = pd.DataFrame(data=np.arange(date.shape[0]), index=date)\n",
    "    return idx.loc[start:end, :].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhsL1dFOTupQ"
   },
   "source": [
    "# Seperate training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ts5me2dHS9JS"
   },
   "outputs": [],
   "source": [
    "data0 = loadmat('drive//MyDrive//data//OD_3m.mat')\n",
    "data0 = data0['OD']\n",
    "data0 = remove_weekends(data0, start=5)\n",
    "train_idx = start_end_idx('2017-07-03', '2017-08-11', weekend=False, night=False)\n",
    "test_idx = start_end_idx('2017-08-14', '2017-08-25', weekend=False, night=False)\n",
    "num_s = 159\n",
    "\n",
    "# Calculate the HA\n",
    "data = data0.astype(np.float64)\n",
    "data_mean = data[:, train_idx].reshape([num_s*num_s, 36, -1], order='F')\n",
    "data_mean = data_mean.mean(axis=2)\n",
    "\n",
    "# Subtract the mean of the training set\n",
    "for i in range(65):\n",
    "    data[:, i*36:(i+1)*36] = data[:, i*36:(i+1)*36] - data_mean\n",
    "\n",
    "h = 10\n",
    "train_data = data[:, train_idx].reshape([159, 159, -1], order='F').transpose([2,0,1])\n",
    "test_data = data[:, test_idx[0]-h:test_idx[-1]+1].reshape([159, 159, -1], order='F').transpose([2,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZYulGK6l5iL"
   },
   "source": [
    "# Define and train ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvS-iwqYjSUt"
   },
   "outputs": [],
   "source": [
    "class Data(keras.utils.Sequence):\n",
    "    def __init__(self, data, h=10, batch_size=32, locs=np.array([1,2])):\n",
    "        # locs is the idx of the x_start location in the data\n",
    "        self.batch_size = batch_size\n",
    "        self.h = h\n",
    "        self.data = data  # (time, O, D)\n",
    "        self.loc_length = len(locs)\n",
    "        self.locs = locs\n",
    "        self.length = int(np.ceil(len(locs) / batch_size))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Only allows positive idx\n",
    "        if idx < 0:\n",
    "            raise ValueError('idx must be positive')\n",
    "        x_start = self.batch_size * idx\n",
    "        x_end = np.min([self.loc_length, self.batch_size * (idx + 1)])\n",
    "\n",
    "        batch_x = np.zeros([x_end-x_start, self.h, num_s, num_s, 1], dtype=self.data.dtype)\n",
    "        batch_y = np.zeros([x_end-x_start, num_s, num_s, 1], dtype=self.data.dtype)\n",
    "        for i, s in enumerate(range(x_start, x_end)):\n",
    "            ss = self.locs[s]\n",
    "            batch_x[i, :, :, :, :] = self.data[ss:(ss+self.h), :, :, np.newaxis]\n",
    "            batch_y[i, :, :, :] = self.data[ss+self.h, :, :, np.newaxis]\n",
    "\n",
    "        return (batch_x, batch_y)\n",
    "\n",
    "trainable_length = train_data.shape[0]-h\n",
    "reset_random_seeds(1)\n",
    "random_idx = np.random.permutation(trainable_length)\n",
    "train_idx = random_idx[0:int(np.floor(trainable_length*0.8))]\n",
    "validate_idx = random_idx[int(np.floor(trainable_length*0.8)):]\n",
    "\n",
    "train_Data = Data(train_data, h=10, batch_size=32, locs=train_idx)\n",
    "validate_Data = Data(train_data, h=10, batch_size=32, locs=validate_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ybhCV5Mjh55",
    "outputId": "92d22a5f-282f-4be5-c972-4e2be237f65d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, None, 159, 159, 8) 2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 159, 159, 8) 32        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, None, 159, 159, 8) 4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 159, 159, 8) 32        \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, 159, 159, 1)       328       \n",
      "=================================================================\n",
      "Total params: 7,656\n",
      "Trainable params: 7,624\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'drive//MyDrive//data//Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt'\n",
    "\n",
    "call_back = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=20, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 )\n",
    "\n",
    "start = time.time()\n",
    "reset_random_seeds(1)\n",
    "seq = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(\n",
    "            shape=(None, num_s, num_s, 1)\n",
    "        ),  # Variable-length sequence of num_s x num_s x 1 frames\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=8, kernel_size=(3, 3), padding=\"same\", return_sequences=True,\n",
    "            data_format='channels_last'\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=8, kernel_size=(3, 3), padding=\"same\", return_sequences=True,\n",
    "            data_format='channels_last'\n",
    "        ),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=1, kernel_size=(3, 3), padding=\"same\", return_sequences=False,\n",
    "            data_format='channels_last'\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "seq.compile(loss=\"mean_squared_error\", optimizer=\"RMSprop\")\n",
    "seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJDKHlQGj4gA",
    "outputId": "adfc924d-1af8-4586-eb96-334ed8fb8991"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "27/27 - 111s - loss: 8.9392 - val_loss: 9.0662\n",
      "\n",
      "Epoch 00001: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 2/200\n",
      "27/27 - 100s - loss: 8.8325 - val_loss: 9.0520\n",
      "\n",
      "Epoch 00002: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 3/200\n",
      "27/27 - 100s - loss: 8.8122 - val_loss: 9.0403\n",
      "\n",
      "Epoch 00003: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 4/200\n",
      "27/27 - 100s - loss: 8.8045 - val_loss: 9.0335\n",
      "\n",
      "Epoch 00004: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 5/200\n",
      "27/27 - 100s - loss: 8.7986 - val_loss: 9.0188\n",
      "\n",
      "Epoch 00005: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 6/200\n",
      "27/27 - 100s - loss: 8.7972 - val_loss: 9.0079\n",
      "\n",
      "Epoch 00006: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 7/200\n",
      "27/27 - 100s - loss: 8.7950 - val_loss: 9.0010\n",
      "\n",
      "Epoch 00007: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 8/200\n",
      "27/27 - 100s - loss: 8.7931 - val_loss: 8.9907\n",
      "\n",
      "Epoch 00008: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 9/200\n",
      "27/27 - 100s - loss: 8.7921 - val_loss: 8.9846\n",
      "\n",
      "Epoch 00009: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 10/200\n",
      "27/27 - 100s - loss: 8.7904 - val_loss: 8.9774\n",
      "\n",
      "Epoch 00010: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 11/200\n",
      "27/27 - 100s - loss: 8.7890 - val_loss: 8.9728\n",
      "\n",
      "Epoch 00011: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 12/200\n",
      "27/27 - 100s - loss: 8.7887 - val_loss: 8.9737\n",
      "\n",
      "Epoch 00012: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 13/200\n",
      "27/27 - 100s - loss: 8.7883 - val_loss: 8.9675\n",
      "\n",
      "Epoch 00013: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 14/200\n",
      "27/27 - 100s - loss: 8.7878 - val_loss: 8.9670\n",
      "\n",
      "Epoch 00014: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 15/200\n",
      "27/27 - 100s - loss: 8.7866 - val_loss: 8.9658\n",
      "\n",
      "Epoch 00015: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 16/200\n",
      "27/27 - 100s - loss: 8.7865 - val_loss: 8.9630\n",
      "\n",
      "Epoch 00016: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 17/200\n",
      "27/27 - 100s - loss: 8.7853 - val_loss: 8.9634\n",
      "\n",
      "Epoch 00017: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 18/200\n",
      "27/27 - 100s - loss: 8.7856 - val_loss: 8.9624\n",
      "\n",
      "Epoch 00018: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 19/200\n",
      "27/27 - 100s - loss: 8.7845 - val_loss: 8.9675\n",
      "\n",
      "Epoch 00019: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 20/200\n",
      "27/27 - 100s - loss: 8.7843 - val_loss: 8.9641\n",
      "\n",
      "Epoch 00020: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 21/200\n",
      "27/27 - 100s - loss: 8.7841 - val_loss: 8.9628\n",
      "\n",
      "Epoch 00021: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 22/200\n",
      "27/27 - 100s - loss: 8.7830 - val_loss: 8.9603\n",
      "\n",
      "Epoch 00022: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 23/200\n",
      "27/27 - 100s - loss: 8.7830 - val_loss: 8.9612\n",
      "\n",
      "Epoch 00023: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 24/200\n",
      "27/27 - 100s - loss: 8.7820 - val_loss: 8.9600\n",
      "\n",
      "Epoch 00024: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 25/200\n",
      "27/27 - 100s - loss: 8.7822 - val_loss: 8.9611\n",
      "\n",
      "Epoch 00025: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 26/200\n",
      "27/27 - 100s - loss: 8.7813 - val_loss: 8.9604\n",
      "\n",
      "Epoch 00026: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 27/200\n",
      "27/27 - 100s - loss: 8.7814 - val_loss: 8.9596\n",
      "\n",
      "Epoch 00027: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 28/200\n",
      "27/27 - 100s - loss: 8.7805 - val_loss: 8.9603\n",
      "\n",
      "Epoch 00028: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 29/200\n",
      "27/27 - 101s - loss: 8.7806 - val_loss: 8.9603\n",
      "\n",
      "Epoch 00029: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 30/200\n",
      "27/27 - 101s - loss: 8.7802 - val_loss: 8.9603\n",
      "\n",
      "Epoch 00030: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 31/200\n",
      "27/27 - 100s - loss: 8.7798 - val_loss: 8.9598\n",
      "\n",
      "Epoch 00031: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 32/200\n",
      "27/27 - 100s - loss: 8.7796 - val_loss: 8.9618\n",
      "\n",
      "Epoch 00032: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 33/200\n",
      "27/27 - 100s - loss: 8.7795 - val_loss: 8.9597\n",
      "\n",
      "Epoch 00033: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 34/200\n",
      "27/27 - 101s - loss: 8.7788 - val_loss: 8.9596\n",
      "\n",
      "Epoch 00034: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 35/200\n",
      "27/27 - 100s - loss: 8.7787 - val_loss: 8.9595\n",
      "\n",
      "Epoch 00035: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 36/200\n",
      "27/27 - 100s - loss: 8.7787 - val_loss: 8.9598\n",
      "\n",
      "Epoch 00036: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 37/200\n",
      "27/27 - 100s - loss: 8.7780 - val_loss: 8.9594\n",
      "\n",
      "Epoch 00037: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 38/200\n",
      "27/27 - 101s - loss: 8.7784 - val_loss: 8.9600\n",
      "\n",
      "Epoch 00038: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 39/200\n",
      "27/27 - 100s - loss: 8.7774 - val_loss: 8.9597\n",
      "\n",
      "Epoch 00039: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 40/200\n",
      "27/27 - 100s - loss: 8.7774 - val_loss: 8.9604\n",
      "\n",
      "Epoch 00040: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 41/200\n",
      "27/27 - 100s - loss: 8.7771 - val_loss: 8.9597\n",
      "\n",
      "Epoch 00041: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 42/200\n",
      "27/27 - 100s - loss: 8.7773 - val_loss: 8.9591\n",
      "\n",
      "Epoch 00042: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 43/200\n",
      "27/27 - 101s - loss: 8.7766 - val_loss: 8.9611\n",
      "\n",
      "Epoch 00043: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 44/200\n",
      "27/27 - 101s - loss: 8.7767 - val_loss: 8.9590\n",
      "\n",
      "Epoch 00044: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 45/200\n",
      "27/27 - 100s - loss: 8.7762 - val_loss: 8.9615\n",
      "\n",
      "Epoch 00045: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 46/200\n",
      "27/27 - 100s - loss: 8.7760 - val_loss: 8.9588\n",
      "\n",
      "Epoch 00046: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 47/200\n",
      "27/27 - 100s - loss: 8.7754 - val_loss: 8.9686\n",
      "\n",
      "Epoch 00047: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 48/200\n",
      "27/27 - 101s - loss: 8.7760 - val_loss: 8.9649\n",
      "\n",
      "Epoch 00048: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 49/200\n",
      "27/27 - 100s - loss: 8.7751 - val_loss: 8.9598\n",
      "\n",
      "Epoch 00049: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 50/200\n",
      "27/27 - 100s - loss: 8.7755 - val_loss: 8.9585\n",
      "\n",
      "Epoch 00050: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 51/200\n",
      "27/27 - 100s - loss: 8.7754 - val_loss: 8.9591\n",
      "\n",
      "Epoch 00051: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 52/200\n",
      "27/27 - 100s - loss: 8.7748 - val_loss: 8.9587\n",
      "\n",
      "Epoch 00052: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 53/200\n",
      "27/27 - 100s - loss: 8.7743 - val_loss: 8.9672\n",
      "\n",
      "Epoch 00053: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 54/200\n",
      "27/27 - 100s - loss: 8.7742 - val_loss: 8.9588\n",
      "\n",
      "Epoch 00054: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 55/200\n",
      "27/27 - 100s - loss: 8.7745 - val_loss: 8.9589\n",
      "\n",
      "Epoch 00055: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 56/200\n",
      "27/27 - 100s - loss: 8.7741 - val_loss: 8.9594\n",
      "\n",
      "Epoch 00056: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 57/200\n",
      "27/27 - 100s - loss: 8.7737 - val_loss: 8.9598\n",
      "\n",
      "Epoch 00057: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 58/200\n",
      "27/27 - 100s - loss: 8.7734 - val_loss: 8.9597\n",
      "\n",
      "Epoch 00058: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 59/200\n",
      "27/27 - 100s - loss: 8.7736 - val_loss: 8.9610\n",
      "\n",
      "Epoch 00059: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 60/200\n",
      "27/27 - 100s - loss: 8.7730 - val_loss: 8.9649\n",
      "\n",
      "Epoch 00060: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 61/200\n",
      "27/27 - 100s - loss: 8.7734 - val_loss: 8.9587\n",
      "\n",
      "Epoch 00061: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 62/200\n",
      "27/27 - 100s - loss: 8.7730 - val_loss: 8.9596\n",
      "\n",
      "Epoch 00062: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 63/200\n",
      "27/27 - 100s - loss: 8.7722 - val_loss: 8.9592\n",
      "\n",
      "Epoch 00063: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 64/200\n",
      "27/27 - 100s - loss: 8.7723 - val_loss: 8.9600\n",
      "\n",
      "Epoch 00064: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 65/200\n",
      "27/27 - 100s - loss: 8.7726 - val_loss: 8.9591\n",
      "\n",
      "Epoch 00065: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 66/200\n",
      "27/27 - 100s - loss: 8.7722 - val_loss: 8.9598\n",
      "\n",
      "Epoch 00066: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 67/200\n",
      "27/27 - 100s - loss: 8.7718 - val_loss: 8.9591\n",
      "\n",
      "Epoch 00067: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 68/200\n",
      "27/27 - 100s - loss: 8.7721 - val_loss: 8.9594\n",
      "\n",
      "Epoch 00068: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 69/200\n",
      "27/27 - 100s - loss: 8.7717 - val_loss: 8.9684\n",
      "\n",
      "Epoch 00069: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "Epoch 70/200\n",
      "27/27 - 100s - loss: 8.7719 - val_loss: 8.9593\n",
      "\n",
      "Epoch 00070: saving model to drive//MyDrive//data/Guangzhou_train_sub_mean10__8(3)_8(3)_1(3)_20210911.ckpt\n",
      "total time is 7124.14s\n"
     ]
    }
   ],
   "source": [
    "seq.fit(\n",
    "    x=train_Data,\n",
    "    epochs=200,\n",
    "    steps_per_epoch=len(train_Data),\n",
    "    verbose=2,\n",
    "    shuffle=True,\n",
    "    validation_data=validate_Data,\n",
    "    validation_steps=len(validate_Data),\n",
    "    callbacks=[call_back, cp_callback],\n",
    ")\n",
    "print(\"total time is {:.2f}s\".format(time.time()-start))\n",
    "seq.save_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTGOFK4Ej3qp"
   },
   "outputs": [],
   "source": [
    "# seq.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRX9Ll1CeXKD"
   },
   "source": [
    "# Multi-step forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_MnGOBjdwd3",
    "outputId": "2caf4fba-8ef0-49fe-eebe-c9f1c63e1fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The result of 1-step prediction: \n",
      "\n",
      "RMSE of OD: 3.250806166277026\n",
      "WMAPE of OD: 0.3011121218477836\n",
      "SMAPE of OD: 0.47549633962236076\n",
      "MAE of OD: 1.5300519326137743\n",
      "r2 of OD: 0.9507375636573557\n",
      "\n",
      "\n",
      "RMSE of flow: 117.1182861328125\n",
      "WMAPE of flow: 0.06865779310464859\n",
      "SMAPE of flow: 0.10691636055707932\n",
      "MAE of flow: 55.47085952758789\n",
      "r2 of flow: 0.985508790218715\n",
      "\n",
      " The result of 2-step prediction: \n",
      "\n",
      "RMSE of OD: 3.2603699809348075\n",
      "WMAPE of OD: 0.3018028847765579\n",
      "SMAPE of OD: 0.47587241240698525\n",
      "MAE of OD: 1.533561931306831\n",
      "r2 of OD: 0.9504472788327615\n",
      "\n",
      "\n",
      "RMSE of flow: 121.16481018066406\n",
      "WMAPE of flow: 0.07187524437904358\n",
      "SMAPE of flow: 0.11043046414852142\n",
      "MAE of flow: 58.070343017578125\n",
      "r2 of flow: 0.9844901254882937\n",
      "\n",
      " The result of 3-step prediction: \n",
      "\n",
      "RMSE of OD: 3.267754385440256\n",
      "WMAPE of OD: 0.3023446826766079\n",
      "SMAPE of OD: 0.4762756235971871\n",
      "MAE of OD: 1.5363149886031313\n",
      "r2 of OD: 0.9502225609496643\n",
      "\n",
      "\n",
      "RMSE of flow: 123.35026550292969\n",
      "WMAPE of flow: 0.07342856377363205\n",
      "SMAPE of flow: 0.11215408891439438\n",
      "MAE of flow: 59.32532501220703\n",
      "r2 of flow: 0.9839255769287578\n"
     ]
    }
   ],
   "source": [
    "real_OD = data0[:, test_idx]\n",
    "real_flow = od2flow(real_OD, num_s=num_s)\n",
    "\n",
    "t_data = data[:, test_idx[0]-h-2:test_idx[-1]+1].reshape([num_s, num_s, -1], order='F').transpose([2,0,1])\n",
    "n = t_data.shape[0]\n",
    "results = {step+1: np.zeros((n-h, num_s, num_s)) for step in range(3)}\n",
    "\n",
    "for i in range(n-h):\n",
    "    X1 = t_data[np.newaxis, i:i+h, :, :, np.newaxis]\n",
    "    results[1][i, :, :] = seq.predict(X1).squeeze()\n",
    "    X2 = np.concatenate([X1[:, 1:, :, :, :], results[1][np.newaxis, [i], :, :, np.newaxis]], axis=1)\n",
    "    results[2][i, :, :] = seq.predict(X2).squeeze()\n",
    "    X3 = np.concatenate([X2[:, 1:, :, :, :], results[2][np.newaxis, [i], :, :, np.newaxis]], axis=1)\n",
    "    results[3][i, :, :] = seq.predict(X3).squeeze()\n",
    "\n",
    "# 1-step forecast results\n",
    "predict_OD1 = results[1][2:, :,:].transpose([1,2,0]).reshape([num_s*num_s, -1], order='F')\n",
    "for i in range(predict_OD1.shape[1]):\n",
    "    predict_OD1[:, i] += data_mean[:, i%36]\n",
    "predict_flow1 = od2flow(predict_OD1, num_s=num_s)\n",
    "print(\"\\n The result of 1-step prediction: \\n\")\n",
    "get_score(real_OD, predict_OD1, real_flow, predict_flow1)\n",
    "\n",
    "# 2-step forecast results\n",
    "predict_OD2 = results[2][1:-1, :,:].transpose([1,2,0]).reshape([num_s*num_s, -1], order='F')\n",
    "for i in range(predict_OD2.shape[1]):\n",
    "    predict_OD2[:, i] += data_mean[:, i%36]\n",
    "predict_flow2 = od2flow(predict_OD2, num_s=num_s)\n",
    "print(\"\\n The result of 2-step prediction: \\n\")\n",
    "get_score(real_OD, predict_OD2, real_flow, predict_flow2)\n",
    "\n",
    "# 3-step forecast results\n",
    "predict_OD3 = results[3][0:-2, :,:].transpose([1,2,0]).reshape([num_s*num_s, -1], order='F')\n",
    "for i in range(predict_OD3.shape[1]):\n",
    "    predict_OD3[:, i] += data_mean[:, i%36]\n",
    "predict_flow3 = od2flow(predict_OD3, num_s=num_s)\n",
    "print(\"\\n The result of 3-step prediction: \\n\")\n",
    "get_score(real_OD, predict_OD3, real_flow, predict_flow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQRr9cIavBgi"
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('/content/drive/MyDrive/data/Guangzhou_OD_ConvLSTM_step1.npz', data=predict_OD1)\n",
    "np.savez_compressed('/content/drive/MyDrive/data/Guangzhou_OD_ConvLSTM_step2.npz', data=predict_OD2)\n",
    "np.savez_compressed('/content/drive/MyDrive/data/Guangzhou_OD_ConvLSTM_step3.npz', data=predict_OD3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Guangzhou_ConvLSTM_timed.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
