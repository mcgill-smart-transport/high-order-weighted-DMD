{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Temporal regularized matrix factorization (TRMF) for metro OD forecasting. Code is adapted from [https://github.com/xinychen/transdim](https://github.com/xinychen/transdim).\n",
    "\n",
    "Original paper for TRMF:\n",
    "- Hsiang-Fu Yu, Nikhil Rao, Inderjit S. Dhillon, 2016. Temporal regularized matrix factorization for high-dimensional time series prediction. 30th Conference on Neural Information Processing Systems (NIPS 2016).\n",
    "\n",
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from numpy.linalg import inv as inv\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def reset_random_seeds(n=1):\n",
    "    os.environ['PYTHONHASHSEED'] = str(n)\n",
    "    np.random.seed(n)\n",
    "    random.seed(n)\n",
    "\n",
    "def ar4cast(theta, X, time_lags, multi_step):\n",
    "    dim, rank = X.shape\n",
    "    d = time_lags.shape[0]\n",
    "    X_new = np.append(X, np.zeros((multi_step, rank)), axis = 0)\n",
    "    for t in range(multi_step):\n",
    "        X_new[dim + t, :] = np.einsum('kr, kr -> r', theta, X_new[dim + t - time_lags, :])\n",
    "    return X_new\n",
    "\n",
    "def TRMF(dense_mat, sparse_mat, init_para, init_hyper, time_lags, maxiter):\n",
    "    \"\"\"Temporal Regularized Matrix Factorization, TRMF.\"\"\"\n",
    "\n",
    "    ## Initialize parameters\n",
    "    W = init_para[\"W\"]\n",
    "    X = init_para[\"X\"]\n",
    "    theta = init_para[\"theta\"]\n",
    "\n",
    "    ## Set hyperparameters\n",
    "    lambda_w = init_hyper[\"lambda_w\"]\n",
    "    lambda_x = init_hyper[\"lambda_x\"]\n",
    "    lambda_theta = init_hyper[\"lambda_theta\"]\n",
    "    eta = init_hyper[\"eta\"]\n",
    "\n",
    "    dim1, dim2 = sparse_mat.shape\n",
    "    pos_train = np.where(sparse_mat != 0)\n",
    "    pos_test = np.where((dense_mat != 0) & (sparse_mat == 0))\n",
    "    binary_mat = sparse_mat.copy()\n",
    "    binary_mat[pos_train] = 1\n",
    "    d, rank = theta.shape\n",
    "\n",
    "    for it in range(maxiter):\n",
    "        ## Update spatial matrix W\n",
    "        for i in range(dim1):\n",
    "            pos0 = np.where(sparse_mat[i, :] != 0)\n",
    "            Xt = X[pos0[0], :]\n",
    "            vec0 = Xt.T @ sparse_mat[i, pos0[0]]\n",
    "            mat0 = inv(Xt.T @ Xt + lambda_w * np.eye(rank))\n",
    "            W[i, :] = mat0 @ vec0\n",
    "        ## Update temporal matrix X\n",
    "        for t in range(dim2):\n",
    "            pos0 = np.where(sparse_mat[:, t] != 0)\n",
    "            Wt = W[pos0[0], :]\n",
    "            Mt = np.zeros((rank, rank))\n",
    "            Nt = np.zeros(rank)\n",
    "            if t < np.max(time_lags):\n",
    "                Pt = np.zeros((rank, rank))\n",
    "                Qt = np.zeros(rank)\n",
    "            else:\n",
    "                Pt = np.eye(rank)\n",
    "                Qt = np.einsum('ij, ij -> j', theta, X[t - time_lags, :])\n",
    "            if t < dim2 - np.min(time_lags):\n",
    "                if t >= np.max(time_lags) and t < dim2 - np.max(time_lags):\n",
    "                    index = list(range(0, d))\n",
    "                else:\n",
    "                    index = list(np.where((t + time_lags >= np.max(time_lags)) & (t + time_lags < dim2)))[0]\n",
    "                for k in index:\n",
    "                    Ak = theta[k, :]\n",
    "                    Mt += np.diag(Ak ** 2)\n",
    "                    theta0 = theta.copy()\n",
    "                    theta0[k, :] = 0\n",
    "                    Nt += np.multiply(Ak, X[t + time_lags[k], :]\n",
    "                                      - np.einsum('ij, ij -> j', theta0, X[t + time_lags[k] - time_lags, :]))\n",
    "            vec0 = Wt.T @ sparse_mat[pos0[0], t] + lambda_x * Nt + lambda_x * Qt\n",
    "            mat0 = inv(Wt.T @ Wt + lambda_x * Mt + lambda_x * Pt + lambda_x * eta * np.eye(rank))\n",
    "            X[t, :] = mat0 @ vec0\n",
    "        ## Update AR coefficients theta\n",
    "        for k in range(d):\n",
    "            theta0 = theta.copy()\n",
    "            theta0[k, :] = 0\n",
    "            mat0 = np.zeros((dim2 - np.max(time_lags), rank))\n",
    "            for L in range(d):\n",
    "                mat0 += X[np.max(time_lags) - time_lags[L] : dim2 - time_lags[L] , :] @ np.diag(theta0[L, :])\n",
    "            VarPi = X[np.max(time_lags) : dim2, :] - mat0\n",
    "            var1 = np.zeros((rank, rank))\n",
    "            var2 = np.zeros(rank)\n",
    "            for t in range(np.max(time_lags), dim2):\n",
    "                B = X[t - time_lags[k], :]\n",
    "                var1 += np.diag(np.multiply(B, B))\n",
    "                var2 += np.diag(B) @ VarPi[t - np.max(time_lags), :]\n",
    "            theta[k, :] = inv(var1 + lambda_theta * np.eye(rank) / lambda_x) @ var2\n",
    "\n",
    "        X_new = ar4cast(theta, X, time_lags, multi_step)\n",
    "        mat_new = W @ X_new[- multi_step :, :].T\n",
    "        mat_hat = W @ X.T\n",
    "    mat_hat = np.append(mat_hat, mat_new, axis = 1)\n",
    "\n",
    "    return mat_hat, W, X_new, theta\n",
    "\n",
    "\n",
    "def update_x_partial(sparse_mat, W, X, theta, lambda_x, eta, time_lags, back_step):\n",
    "    d = time_lags.shape[0]\n",
    "    dim2, rank = X.shape\n",
    "    tmax = np.max(time_lags)\n",
    "    for t in range(dim2 - back_step, dim2):\n",
    "        pos0 = np.where(sparse_mat[:, t] != 0)\n",
    "        Wt = W[pos0[0], :]\n",
    "        Mt = np.zeros((rank, rank))\n",
    "        Nt = np.zeros(rank)\n",
    "        if t < tmax:\n",
    "            Pt = np.zeros((rank, rank))\n",
    "            Qt = np.zeros(rank)\n",
    "        else:\n",
    "            Pt = np.eye(rank)\n",
    "            Qt = np.einsum('ij, ij -> j', theta, X[t - time_lags, :])\n",
    "        if t < dim2 - np.min(time_lags):\n",
    "            if t >= tmax and t < dim2 - tmax:\n",
    "                index = list(range(0, d))\n",
    "            else:\n",
    "                index = list(np.where((t + time_lags >= tmax) & (t + time_lags < dim2)))[0]\n",
    "            for k in index:\n",
    "                Ak = theta[k, :]\n",
    "                Mt += np.diag(Ak ** 2)\n",
    "                theta0 = theta.copy()\n",
    "                theta0[k, :] = 0\n",
    "                Nt += np.multiply(Ak, X[t + time_lags[k], :]\n",
    "                                  - np.einsum('ij, ij -> j', theta0, X[t + time_lags[k] - time_lags, :]))\n",
    "        vec0 = Wt.T @ sparse_mat[pos0[0], t] + lambda_x * Nt + lambda_x * Qt\n",
    "        mat0 = inv(Wt.T @ Wt + lambda_x * Mt + lambda_x * Pt + lambda_x * eta * np.eye(rank))\n",
    "        X[t, :] = mat0 @ vec0\n",
    "    return X\n",
    "\n",
    "\n",
    "def TRMF_partial(dense_mat, sparse_mat, init_para, init_hyper, time_lags, maxiter):\n",
    "    ## Initialize parameters\n",
    "    W = init_para[\"W\"]\n",
    "    X = init_para[\"X\"]\n",
    "    theta = init_para[\"theta\"]\n",
    "    ## Set hyperparameters\n",
    "    lambda_x = init_hyper[\"lambda_x\"]\n",
    "    eta = init_hyper[\"eta\"]\n",
    "    back_step = 10 * multi_step\n",
    "    for it in range(maxiter):\n",
    "        X = update_x_partial(sparse_mat, W, X, theta, lambda_x, eta, time_lags, back_step)\n",
    "    X_new = ar4cast(theta, X, time_lags, multi_step)\n",
    "    mat_hat = W @ X_new[- multi_step :, :].T\n",
    "    mat_hat[mat_hat < 0] = 0\n",
    "\n",
    "    return mat_hat, W, X_new, theta\n",
    "\n",
    "\n",
    "def TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter, maxiter2=10):\n",
    "    dim1, T = dense_mat.shape\n",
    "    d = time_lags.shape[0]\n",
    "    start_time = T - pred_step\n",
    "    results = {step + 1: np.zeros((dim1, pred_time_steps)) for step in range(multi_step)}\n",
    "    for t in range(pred_time_steps):\n",
    "        if t == 0:\n",
    "            init_para = {\"W\": 0.1 * np.random.randn(dim1, rank),\n",
    "                         \"X\": 0.1 * np.random.randn(start_time, rank),\n",
    "                         \"theta\": 0.1 * np.random.randn(d, rank)}\n",
    "            mat, W, X_new, theta = TRMF(dense_mat[:, 0 : start_time], sparse_mat[:, 0 : start_time],\n",
    "                                        init_para, init_hyper, time_lags, maxiter)\n",
    "            X_new = X_new[0: (start_time + t), :]\n",
    "        else:\n",
    "            init_para = {\"W\": W, \"X\": X_new, \"theta\": theta}\n",
    "            mat, W, X_new, theta = TRMF_partial(dense_mat[:, 0 : start_time + t],\n",
    "                                                sparse_mat[:, 0 : start_time + t],\n",
    "                                                init_para, init_hyper, time_lags, maxiter2)\n",
    "            X_new = X_new[0: (start_time + t), :]\n",
    "        for step in range(multi_step):\n",
    "            results[step+1][:, t] = mat[:, -multi_step+step]\n",
    "\n",
    "        if (t + 1) % 36 == 0:\n",
    "            print('Time step: {}'.format(t + 1))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data0 = loadmat('..//data//OD_3m.mat')\n",
    "data0 = data0['OD']\n",
    "data0 = remove_weekends(data0, start=5)\n",
    "\n",
    "train_idx = start_end_idx('2017-07-03', '2017-08-11', weekend=False, night=False)\n",
    "test_idx = start_end_idx('2017-08-14', '2017-08-25', weekend=False, night=False)\n",
    "num_s = 159\n",
    "\n",
    "# Subtract the mean in the training set\n",
    "data = data0.astype(np.float64)\n",
    "data_mean = data[:, train_idx].reshape([num_s * num_s, 36, -1], order='F')\n",
    "data_mean = data_mean.mean(axis=2)\n",
    "for i in range(65):\n",
    "    data[:, i * 36:(i + 1) * 36] = data[:, i * 36:(i + 1) * 36] - data_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Parameter tuning\n",
    "# Tune weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "weight=500, time=1455.6347873210907\n",
      "[2.900143570307469]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "weight=1000, time=2894.059718847275\n",
      "[2.900143570307469, 2.8908132436414737]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "weight=1500, time=4386.530678510666\n",
      "[2.900143570307469, 2.8908132436414737, 2.887279262451144]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "weight=2000, time=5876.678242921829\n",
      "[2.900143570307469, 2.8908132436414737, 2.887279262451144, 2.8858583241754587]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "weight=2500, time=7373.742558956146\n",
      "[2.900143570307469, 2.8908132436414737, 2.887279262451144, 2.8858583241754587, 2.8886148587884266]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "weight=3000, time=8723.161129713058\n",
      "[2.900143570307469, 2.8908132436414737, 2.887279262451144, 2.8858583241754587, 2.8886148587884266, 2.892002191351582]\n",
      "[2.900143570307469, 2.8908132436414737, 2.887279262451144, 2.8858583241754587, 2.8886148587884266, 2.892002191351582]\n",
      "best_weight is 2000\n"
     ]
    }
   ],
   "source": [
    "multi_step = 1\n",
    "pred_time_steps = 36 * 10 + (multi_step - 1)\n",
    "train_data = data[:, train_idx]\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "d = time_lags.shape[0]\n",
    "maxiter = 100\n",
    "# Tune weights\n",
    "eta = 0.03\n",
    "rank = 40\n",
    "rmse_list = []\n",
    "weights = [500, 1000, 1500, 2000, 2500, 3000]\n",
    "start = time.time()\n",
    "reset_random_seeds(1)\n",
    "for weight in weights:\n",
    "    init_hyper = {\"lambda_w\": weight, \"lambda_x\": weight, \"lambda_theta\": weight, \"eta\": eta}\n",
    "    results = TRMF_forecast(train_data, train_data, init_hyper, pred_time_steps, multi_step, rank, time_lags, maxiter, maxiter2=10)\n",
    "    rmse_list.append(RMSE(train_data[:, -36 * 10:], results[1]))\n",
    "    print('weight={}, time={}'.format(weight, time.time()-start))\n",
    "    print(rmse_list)\n",
    "\n",
    "print(rmse_list)\n",
    "best_weight = weights[np.argmin(rmse_list)]\n",
    "print('best_weight is {}'.format(best_weight))  # was 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tune rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "rank=30, time=9451.268389225006\n",
      "[2.886827073199328]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "rank=40, time=10385.889158248901\n",
      "[2.886827073199328, 2.8857975533554705]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "rank=50, time=11592.862512350082\n",
      "[2.886827073199328, 2.8857975533554705, 2.884032869334924]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "rank=60, time=12940.904308795929\n",
      "[2.886827073199328, 2.8857975533554705, 2.884032869334924, 2.8842425629542205]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "rank=70, time=14576.313164234161\n",
      "[2.886827073199328, 2.8857975533554705, 2.884032869334924, 2.8842425629542205, 2.883423107921175]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "rank=80, time=16396.84063744545\n",
      "[2.886827073199328, 2.8857975533554705, 2.884032869334924, 2.8842425629542205, 2.883423107921175, 2.8840663199765357]\n",
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "rank=90, time=18595.050589084625\n",
      "[2.886827073199328, 2.8857975533554705, 2.884032869334924, 2.8842425629542205, 2.883423107921175, 2.8840663199765357, 2.883652930207042]\n",
      "[2.886827073199328, 2.8857975533554705, 2.884032869334924, 2.8842425629542205, 2.883423107921175, 2.8840663199765357, 2.883652930207042]\n",
      "best_rank is 70\n"
     ]
    }
   ],
   "source": [
    "init_hyper = {\"lambda_w\": best_weight, \"lambda_x\": best_weight, \"lambda_theta\": best_weight, \"eta\": eta}\n",
    "rmse_list = []\n",
    "ranks = range(30, 100, 10)\n",
    "reset_random_seeds(1)\n",
    "for rank in ranks:\n",
    "    results = TRMF_forecast(train_data, train_data, init_hyper, pred_time_steps, multi_step, rank, time_lags, maxiter, maxiter2=10)\n",
    "    rmse_list.append(RMSE(train_data[:, -36 * 10:], results[1]))\n",
    "    print(\"rank={}, time={}\".format(rank, time.time()-start))\n",
    "    print(rmse_list)\n",
    "\n",
    "print(rmse_list)\n",
    "best_rank = ranks[np.argmin(rmse_list)]\n",
    "print(\"best_rank is {}\".format(best_rank))  # was 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Forcast and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step: 36\n",
      "Time step: 72\n",
      "Time step: 108\n",
      "Time step: 144\n",
      "Time step: 180\n",
      "Time step: 216\n",
      "Time step: 252\n",
      "Time step: 288\n",
      "Time step: 324\n",
      "Time step: 360\n",
      "Results of 1-step forecasting:\n",
      "RMSE of OD: 3.2241407008654197\n",
      "WMAPE of OD: 0.3061048452345327\n",
      "SMAPE of OD: 1.0699346036253194\n",
      "MAE of OD: 1.5554216388216273\n",
      "r2 of OD: 0.9515424213773562\n",
      "\n",
      "\n",
      "RMSE of flow: 126.03266906738281\n",
      "WMAPE of flow: 0.07920946925878525\n",
      "SMAPE of flow: 0.16063518822193146\n",
      "MAE of flow: 63.99590301513672\n",
      "r2 of flow: 0.9832188588925608\n",
      "Results of 2-step forecasting:\n",
      "RMSE of OD: 3.244949500526044\n",
      "WMAPE of OD: 0.30723113992705303\n",
      "SMAPE of OD: 1.069674601964555\n",
      "MAE of OD: 1.561144720843063\n",
      "r2 of OD: 0.9509149065780521\n",
      "\n",
      "\n",
      "RMSE of flow: 127.8674545288086\n",
      "WMAPE of flow: 0.08071385324001312\n",
      "SMAPE of flow: 0.16331948339939117\n",
      "MAE of flow: 65.21134948730469\n",
      "r2 of flow: 0.9827267041945928\n",
      "Results of 3-step forecasting:\n",
      "RMSE of OD: 3.257398974035579\n",
      "WMAPE of OD: 0.30787833300154094\n",
      "SMAPE of OD: 1.0698778822739048\n",
      "MAE of OD: 1.5644333264572037\n",
      "r2 of OD: 0.9505375473603562\n",
      "\n",
      "\n",
      "RMSE of flow: 128.6537322998047\n",
      "WMAPE of flow: 0.08131537586450577\n",
      "SMAPE of flow: 0.16508911550045013\n",
      "MAE of flow: 65.69733428955078\n",
      "r2 of flow: 0.9825136161579751\n"
     ]
    }
   ],
   "source": [
    "multi_step = 3\n",
    "pred_time_steps = 36 * 10 + (multi_step - 1)\n",
    "train_data = data[:, np.concatenate([train_idx, test_idx])]\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "maxiter = 200\n",
    "init_hyper = {\"lambda_w\": best_weight, \"lambda_x\": best_weight, \"lambda_theta\": best_weight, \"eta\": eta}\n",
    "reset_random_seeds(1)\n",
    "results = TRMF_forecast(train_data, train_data, init_hyper, pred_time_steps, multi_step, best_rank, time_lags, maxiter, maxiter2=10)\n",
    "\n",
    "mat_hat1 = results[1][:, 2:2 + 360].copy()\n",
    "mat_hat2 = results[2][:, 1:1 + 360].copy()\n",
    "mat_hat3 = results[3][:, 0:0 + 360].copy()\n",
    "for i in range(mat_hat1.shape[1]):\n",
    "    mat_hat1[:, i] += data_mean[:, i % 36]\n",
    "    mat_hat2[:, i] += data_mean[:, i % 36]\n",
    "    mat_hat3[:, i] += data_mean[:, i % 36]\n",
    "\n",
    "real_OD = data0[:, test_idx]\n",
    "real_flow = od2flow(real_OD, num_s=num_s)\n",
    "print('Results of 1-step forecasting:')\n",
    "predict_flow1 = od2flow(mat_hat1, num_s=num_s)\n",
    "get_score(real_OD, mat_hat1, real_flow, predict_flow1)\n",
    "\n",
    "print('Results of 2-step forecasting:')\n",
    "predict_flow2 = od2flow(mat_hat2, num_s=num_s)\n",
    "get_score(real_OD, mat_hat2, real_flow, predict_flow2)\n",
    "\n",
    "print('Results of 3-step forecasting:')\n",
    "predict_flow3 = od2flow(mat_hat3, num_s=num_s)\n",
    "get_score(real_OD, mat_hat3, real_flow, predict_flow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('..//data//Guangzhou_OD_TRMF_step1.npz', data=mat_hat1)\n",
    "np.savez_compressed('..//data//Guangzhou_OD_TRMF_step2.npz', data=mat_hat2)\n",
    "np.savez_compressed('..//data//Guangzhou_OD_TRMF_step3.npz', data=mat_hat3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
